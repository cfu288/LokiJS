{
  "version": 3,
  "sources": ["../../src/storage-adapter/fs-structured-adapter.ts"],
  "sourcesContent": ["/* eslint-disable @typescript-eslint/no-this-alias */\n/*\n  Loki (node) fs structured Adapter (need to require this script to instance and use it).\n\n  This adapter will save database container and each collection to separate files and\n  save collection only if it is dirty.  It is also designed to use a destructured serialization \n  method intended to lower the memory overhead of json serialization.\n  \n  This adapter utilizes ES6 generator/iterator functionality to stream output and\n  uses node linereader module to stream input.  This should lower memory pressure \n  in addition to individual object serializations rather than loki's default deep object\n  serialization.\n*/\nimport fsPromise from \"node:fs/promises\";\nimport fs from \"node:fs\";\nimport readline from \"node:readline\";\nimport stream from \"node:stream\";\nimport { ReferencePersistenceAdapter } from \"./src/models/persistence-adapter\";\nimport Sylvie from \"../sylviejs\";\nimport { PersistenceAdapterCallback } from \"./src/models/persistence-adapter-callback\";\n\n/**\n * Loki structured (node) filesystem adapter class.\n *     This class fulfills the loki 'reference' abstract adapter interface which can be applied to other storage methods.\n */\nexport class FsStructuredAdapter implements ReferencePersistenceAdapter {\n  mode: \"reference\";\n  dbref?: Sylvie;\n  constructor() {\n    this.mode = \"reference\";\n    this.dbref = null;\n  }\n\n  /**\n   * Loki reference adapter interface function.  Saves structured json via loki database object reference.\n   *\n   * @param {string} dbname - the name to give the serialized database within the catalog.\n   * @param {object} dbref - the loki database object reference to save.\n   * @param {function} callback - callback passed obj.success with true or false\n   * @memberof LokiFsStructuredAdapter\n   */\n  exportDatabase(\n    dbname: string,\n    dbref: Sylvie,\n    callback?: PersistenceAdapterCallback,\n  ): void {\n    this.dbref = dbref;\n\n    // create (dirty) partition generator/iterator\n    const pi = this.#getPartition();\n\n    this.#saveNextPartition(dbname, pi, () => {\n      callback({ success: true });\n    });\n  }\n\n  deleteDatabase(dbName: string, callback: PersistenceAdapterCallback): void {\n    fsPromise\n      .readdir(\".\")\n      .then((files) => {\n        for (const file of files) {\n          if (file === dbName || file.startsWith(dbName + \".\") === true) {\n            fsPromise.unlink(file).catch((err) => {\n              callback(err);\n              return;\n            });\n          }\n        }\n        callback({ success: true });\n      })\n      .catch((err) => {\n        callback(err);\n      });\n  }\n\n  /**\n   * Loki persistence adapter interface function which outputs un-prototype db object reference to load from.\n   *\n   * @param {string} dbname - the name of the database to retrieve.\n   * @param {function} callback - callback should accept string param containing db object reference.\n   * @memberof LokiFsStructuredAdapter\n   */\n  loadDatabase(\n    dbname: string,\n    callback: (value: string | Error | Sylvie | null) => void,\n  ) {\n    let instream;\n    let outstream;\n    let rl;\n    const self = this;\n\n    this.dbref = null;\n\n    // make sure file exists\n    fsPromise\n      .stat(dbname)\n      .then((stats) => {\n        let jsonErr;\n\n        if (!stats.isFile()) {\n          // something exists at this path but it isn't a file.\n          callback(new Error(`${dbname} is not a valid file.`));\n          return;\n        }\n\n        instream = fs.createReadStream(dbname);\n        outstream = new stream();\n        rl = readline.createInterface(instream, outstream);\n\n        // first, load db container component\n        rl.on(\"line\", (line) => {\n          // it should single JSON object (a one line file)\n          if (self.dbref === null && line !== \"\") {\n            try {\n              self.dbref = JSON.parse(line);\n            } catch (e) {\n              jsonErr = e;\n            }\n          }\n        });\n\n        // when that is done, examine its collection array to sequence loading each\n        rl.on(\"close\", () => {\n          if (jsonErr) {\n            // a json error was encountered reading the container file.\n            callback(jsonErr);\n          } else if (self.dbref.collections.length > 0) {\n            self.#loadNextCollection(dbname, 0, () => {\n              callback(self.dbref);\n            });\n          }\n        });\n      })\n      .catch((fileErr) => {\n        if (fileErr.code === \"ENOENT\") {\n          // file does not exist, so callback with null\n          callback(null);\n          return;\n        } else {\n          // some other file system error.\n          callback(fileErr);\n          return;\n        }\n      });\n  }\n\n  /**\n   * Generator for constructing lines for file streaming output of db container or collection.\n   *\n   * @param {object=} options - output format options for use externally to loki\n   * @param {int=} options.partition - can be used to only output an individual collection or db (-1)\n   *\n   * @returns {string|array} A custom, restructured aggregation of independent serializations.\n   * @memberof LokiFsStructuredAdapter\n   */\n  *#generateDestructured(options) {\n    let idx;\n    let dbcopy;\n\n    options = options || {};\n\n    if (!Object.hasOwn(options, \"partition\")) {\n      options.partition = -1;\n    }\n\n    // if partition is -1 we will return database container with no data\n    if (options.partition === -1) {\n      // instantiate lightweight clone and remove its collection data\n      dbcopy = this.dbref.copy();\n\n      for (idx = 0; idx < dbcopy.collections.length; idx++) {\n        dbcopy.collections[idx].data = [];\n      }\n\n      yield dbcopy.serialize({\n        serializationMethod: \"normal\",\n      });\n\n      return;\n    }\n\n    // 'partitioned' along with 'partition' of 0 or greater is a request for single collection serialization\n    if (options.partition >= 0) {\n      let docidx;\n\n      // dbref collections have all data so work against that\n      const doccount = this.dbref.collections[options.partition].data.length;\n\n      for (docidx = 0; docidx < doccount; docidx++) {\n        yield JSON.stringify(\n          this.dbref.collections[options.partition].data[docidx],\n        );\n      }\n    }\n  }\n\n  /**\n   * Recursive function to chain loading of each collection one at a time.\n   * If at some point i can determine how to make async driven generator, this may be converted to generator.\n   *\n   * @param {string} dbname - the name to give the serialized database within the catalog.\n   * @param {int} collectionIndex - the ordinal position of the collection to load.\n   * @param {function} callback - callback to pass to next invocation or to call when done\n   * @memberof LokiFsStructuredAdapter\n   */\n  #loadNextCollection(dbname, collectionIndex, callback) {\n    let instream = fs.createReadStream(`${dbname}.${collectionIndex}`);\n    let outstream = new stream() as unknown as NodeJS.WritableStream;\n    let rl = readline.createInterface(instream, outstream);\n    const self = this;\n    let obj;\n\n    rl.on(\"line\", (line) => {\n      if (line !== \"\") {\n        try {\n          obj = JSON.parse(line);\n        } catch (e) {\n          callback(e);\n        }\n        self.dbref.collections[collectionIndex].data.push(obj);\n      }\n    });\n\n    rl.on(\"close\", (line) => {\n      instream = null;\n      outstream = null;\n      rl = null;\n      obj = null;\n\n      // if there are more collections, load the next one\n      if (++collectionIndex < self.dbref.collections.length) {\n        self.#loadNextCollection(dbname, collectionIndex, callback);\n      }\n      // otherwise we are done, callback to loadDatabase so it can return the new db object representation.\n      else {\n        callback();\n      }\n    });\n  }\n\n  /**\n   * Generator for yielding sequence of dirty partition indices to iterate.\n   */\n  *#getPartition() {\n    let idx;\n    const clen = this.dbref.collections.length;\n\n    // since database container (partition -1) doesn't have dirty flag at db level, always save\n    yield -1;\n\n    // yield list of dirty partitions for iterateration\n    for (idx = 0; idx < clen; idx++) {\n      if (this.dbref.collections[idx].dirty) {\n        yield idx;\n      }\n    }\n  }\n\n  /**\n   * Utility method for queueing one save at a time\n   */\n  #saveNextPartition(dbname, pi, callback: () => void) {\n    const self = this;\n    const pinext = pi.next();\n\n    if (pinext.done) {\n      callback();\n      return;\n    }\n\n    // db container (partition -1) uses just dbname for filename,\n    // otherwise append collection array index to filename\n    const filename = dbname + (pinext.value === -1 ? \"\" : `.${pinext.value}`);\n\n    const wstream = fs.createWriteStream(filename);\n    //wstream.on('finish', function() {\n    wstream.on(\"close\", () => {\n      self.#saveNextPartition(dbname, pi, callback);\n    });\n\n    const li = this.#generateDestructured({ partition: pinext.value });\n\n    // iterate each of the lines generated by generateDestructured()\n    for (const outline of li) {\n      wstream.write(`${outline}\\n`);\n    }\n\n    wstream.end();\n  }\n}\n\nif (typeof window !== \"undefined\") {\n  Object.assign(window, {\n    FsStructuredAdapter: FsStructuredAdapter,\n  });\n}\n"],
  "mappings": "uUAaA,OAAOA,MAAe,mBACtB,OAAOC,MAAQ,UACf,OAAOC,MAAc,gBACrB,OAAOC,MAAY,cAhBnB,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAyBaC,EAAN,KAAiE,CAGtE,aAAc,CA+HdC,EAAA,KAACT,GAkDDS,EAAA,KAAAP,GAsCAO,EAAA,KAACL,GAkBDK,EAAA,KAAAH,GAxOE,KAAK,KAAO,YACZ,KAAK,MAAQ,IACf,CAUA,eACEI,EACAC,EACAC,EACM,CACN,KAAK,MAAQD,EAGb,IAAME,EAAKC,EAAA,KAAKV,EAAAC,GAAL,WAEXS,EAAA,KAAKR,EAAAC,GAAL,UAAwBG,EAAQG,EAAI,IAAM,CACxCD,EAAS,CAAE,QAAS,EAAK,CAAC,CAC5B,EACF,CAEA,eAAeG,EAAgBH,EAA4C,CACzEI,EACG,QAAQ,GAAG,EACX,KAAMC,GAAU,CACf,QAAWC,KAAQD,GACbC,IAASH,GAAUG,EAAK,WAAWH,EAAS,GAAG,IAAM,KACvDC,EAAU,OAAOE,CAAI,EAAE,MAAOC,GAAQ,CACpCP,EAASO,CAAG,CAEd,CAAC,EAGLP,EAAS,CAAE,QAAS,EAAK,CAAC,CAC5B,CAAC,EACA,MAAOO,GAAQ,CACdP,EAASO,CAAG,CACd,CAAC,CACL,CASA,aACET,EACAE,EACA,CACA,IAAIQ,EACAC,EACAC,EACEC,EAAO,KAEb,KAAK,MAAQ,KAGbP,EACG,KAAKN,CAAM,EACX,KAAMc,GAAU,CACf,IAAIC,EAEJ,GAAI,CAACD,EAAM,OAAO,EAAG,CAEnBZ,EAAS,IAAI,MAAM,GAAGF,wBAA6B,CAAC,EACpD,OAGFU,EAAWM,EAAG,iBAAiBhB,CAAM,EACrCW,EAAY,IAAIM,EAChBL,EAAKM,EAAS,gBAAgBR,EAAUC,CAAS,EAGjDC,EAAG,GAAG,OAASO,GAAS,CAEtB,GAAIN,EAAK,QAAU,MAAQM,IAAS,GAClC,GAAI,CACFN,EAAK,MAAQ,KAAK,MAAMM,CAAI,CAC9B,OAASC,EAAP,CACAL,EAAUK,CACZ,CAEJ,CAAC,EAGDR,EAAG,GAAG,QAAS,IAAM,CA1H7B,IAAAS,EA2HcN,EAEFb,EAASa,CAAO,EACPF,EAAK,MAAM,YAAY,OAAS,GACzCT,EAAAiB,EAAAR,EAAKrB,EAAAC,GAAL,KAAA4B,EAAyBrB,EAAQ,EAAG,IAAM,CACxCE,EAASW,EAAK,KAAK,CACrB,EAEJ,CAAC,CACH,CAAC,EACA,MAAOS,GAAY,CAClB,GAAIA,EAAQ,OAAS,SAAU,CAE7BpB,EAAS,IAAI,EACb,WACK,CAELA,EAASoB,CAAO,EAChB,OAEJ,CAAC,CACL,CAiJF,EAxQaC,EAAAzB,EAAA,uBAkIVR,EAAA,YAAAC,EAAqBgC,EAAA,UAACC,EAAS,CAC9B,IAAIC,EACAC,EASJ,GAPAF,EAAUA,GAAW,CAAC,EAEjB,OAAO,OAAOA,EAAS,WAAW,IACrCA,EAAQ,UAAY,IAIlBA,EAAQ,YAAc,GAAI,CAI5B,IAFAE,EAAS,KAAK,MAAM,KAAK,EAEpBD,EAAM,EAAGA,EAAMC,EAAO,YAAY,OAAQD,IAC7CC,EAAO,YAAYD,CAAG,EAAE,KAAO,CAAC,EAGlC,MAAMC,EAAO,UAAU,CACrB,oBAAqB,QACvB,CAAC,EAED,OAIF,GAAIF,EAAQ,WAAa,EAAG,CAC1B,IAAIG,EAGEC,EAAW,KAAK,MAAM,YAAYJ,EAAQ,SAAS,EAAE,KAAK,OAEhE,IAAKG,EAAS,EAAGA,EAASC,EAAUD,IAClC,MAAM,KAAK,UACT,KAAK,MAAM,YAAYH,EAAQ,SAAS,EAAE,KAAKG,CAAM,CACvD,EAGN,EAvCsB,yBAkDtBnC,EAAA,YAAAC,EAAmB8B,EAAA,SAACvB,EAAQ6B,EAAiB3B,EAAU,CACrD,IAAIQ,EAAWM,EAAG,iBAAiB,GAAGhB,KAAU6B,GAAiB,EAC7DlB,EAAY,IAAIM,EAChBL,EAAKM,EAAS,gBAAgBR,EAAUC,CAAS,EAC/CE,EAAO,KACTiB,EAEJlB,EAAG,GAAG,OAASO,GAAS,CACtB,GAAIA,IAAS,GAAI,CACf,GAAI,CACFW,EAAM,KAAK,MAAMX,CAAI,CACvB,OAASC,EAAP,CACAlB,EAASkB,CAAC,CACZ,CACAP,EAAK,MAAM,YAAYgB,CAAe,EAAE,KAAK,KAAKC,CAAG,EAEzD,CAAC,EAEDlB,EAAG,GAAG,QAAUO,GAAS,CA/N7B,IAAAE,EAgOMX,EAAW,KACXC,EAAY,KACZC,EAAK,KACLkB,EAAM,KAGF,EAAED,EAAkBhB,EAAK,MAAM,YAAY,OAC7CT,EAAAiB,EAAAR,EAAKrB,EAAAC,GAAL,KAAA4B,EAAyBrB,EAAQ6B,EAAiB3B,GAIlDA,EAAS,CAEb,CAAC,CACH,EAjCmB,uBAsClBR,EAAA,YAAAC,EAAa4B,EAAA,WAAG,CACf,IAAIE,EACEM,EAAO,KAAK,MAAM,YAAY,OAMpC,IAHA,KAAM,GAGDN,EAAM,EAAGA,EAAMM,EAAMN,IACpB,KAAK,MAAM,YAAYA,CAAG,EAAE,QAC9B,MAAMA,EAGZ,EAbc,iBAkBd7B,EAAA,YAAAC,EAAkB0B,EAAA,SAACvB,EAAQG,EAAID,EAAsB,CACnD,IAAMW,EAAO,KACPmB,EAAS7B,EAAG,KAAK,EAEvB,GAAI6B,EAAO,KAAM,CACf9B,EAAS,EACT,OAKF,IAAM+B,EAAWjC,GAAUgC,EAAO,QAAU,GAAK,GAAK,IAAIA,EAAO,SAE3DE,EAAUlB,EAAG,kBAAkBiB,CAAQ,EAE7CC,EAAQ,GAAG,QAAS,IAAM,CApR9B,IAAAb,EAqRMjB,EAAAiB,EAAAR,EAAKjB,EAAAC,GAAL,KAAAwB,EAAwBrB,EAAQG,EAAID,EACtC,CAAC,EAED,IAAMiC,EAAK/B,EAAA,KAAKd,EAAAC,GAAL,UAA2B,CAAE,UAAWyC,EAAO,KAAM,GAGhE,QAAWI,KAAWD,EACpBD,EAAQ,MAAM,GAAGE;AAAA,CAAW,EAG9BF,EAAQ,IAAI,CACd,EA3BkB,sBA8BhB,OAAO,QAAW,aACpB,OAAO,OAAO,OAAQ,CACpB,oBAAqBpC,CACvB,CAAC",
  "names": ["fsPromise", "fs", "readline", "stream", "_generateDestructured", "generateDestructured_fn", "_loadNextCollection", "loadNextCollection_fn", "_getPartition", "getPartition_fn", "_saveNextPartition", "saveNextPartition_fn", "FsStructuredAdapter", "__privateAdd", "dbname", "dbref", "callback", "pi", "__privateMethod", "dbName", "fsPromise", "files", "file", "err", "instream", "outstream", "rl", "self", "stats", "jsonErr", "fs", "stream", "readline", "line", "e", "_a", "fileErr", "__name", "options", "idx", "dbcopy", "docidx", "doccount", "collectionIndex", "obj", "clen", "pinext", "filename", "wstream", "li", "outline"]
}
