{
  "version": 3,
  "sources": ["../../src/storage-adapter/incremental-indexeddb-adapter.ts"],
  "sourcesContent": ["// @ts-nocheck\n\nimport { IncrementalPersistenceAdapter } from \"./src/models/persistence-adapter\";\n\n/* jshint -W030 */\nconst DEBUG =\n  typeof window !== \"undefined\" && !!window.__loki_incremental_idb_debug;\n\n/**\n * An improved Loki persistence adapter for IndexedDB (not compatible with LokiIndexedAdapter)\n *     Unlike LokiIndexedAdapter, the database is saved not as one big JSON blob, but split into\n *     small chunks with individual collection documents. When saving, only the chunks with changed\n *     documents (and database metadata) is saved to IndexedDB. This speeds up small incremental\n *     saves by an order of magnitude on large (tens of thousands of records) databases. It also\n *     avoids Safari 13 bug that would cause the database to balloon in size to gigabytes\n *\n *     The `appname` argument is not provided - to distinguish between multiple app on the same\n *     domain, simply use a different Loki database name\n *\n * @example\n * var adapter = new IncrementalIndexedDBAdapter();\n *\n * @constructor IncrementalIndexedDBAdapter\n *\n * @param {object=} options Configuration options for the adapter\n * @param {function} options.onversionchange Function to call on `IDBDatabase.onversionchange` event\n *     (most likely database deleted from another browser tab)\n * @param {function} options.onFetchStart Function to call once IDB load has begun.\n *     Use this as an opportunity to execute code concurrently while IDB does work on a separate thread\n * @param {function} options.onDidOverwrite Called when this adapter is forced to overwrite contents\n *     of IndexedDB. This happens if there's another open tab of the same app that's making changes.\n *     You might use it as an opportunity to alert user to the potential loss of data\n * @param {function} options.serializeChunk Called with a chunk (array of Loki documents) before\n *     it's saved to IndexedDB. You can use it to manually compress on-disk representation\n *     for faster database loads. Hint: Hand-written conversion of objects to arrays is very\n *     profitable for performance. If you use this, you must also pass options.deserializeChunk.\n * @param {function} options.deserializeChunk Called with a chunk serialized with options.serializeChunk\n *     Expects an array of Loki documents as the return value\n * @param {number} options.megachunkCount Number of parallel requests for data when loading database.\n *     Can be tuned for a specific application\n * @param {function} options.encrypt Called on each collection name or chunk string (after serialization),\n *     before saving into IDB.\n * @param {function} options.decrypt Called on each collecion name or chunk string after retrieval from IDB.\n */\nexport class IncrementalIndexedDBAdapter\n  implements IncrementalPersistenceAdapter\n{\n  constructor(options) {\n    this.mode = \"incremental\";\n    this.options = options || {};\n    this.chunkSize = 100;\n    this.megachunkCount = this.options.megachunkCount || 20;\n\n    this.idb = null; // will be lazily loaded on first operation that needs it\n    this.idbActualLokiObjectStoreName = null; // will be lazily loaded, same as .idb\n    this.keyResolver = null; // will be lazily loaded, same as .idb\n\n    this._prevLokiVersionId = null;\n    this._prevCollectionVersionIds = {};\n\n    const shouldSetupEncryption = !!this.options.encrypt;\n    if (shouldSetupEncryption) {\n      if (shouldSetupEncryption && !this.options.decrypt) {\n        throw Error(\n          \"encrypt was provided, but decrypt was not. You must pass both functions.\",\n        );\n      }\n      if (shouldSetupEncryption && !isFunction(this.options.encrypt)) {\n        throw Error(\"encrypt was provided, but it is not a function!\");\n      }\n      if (shouldSetupEncryption && !isFunction(this.options.decrypt)) {\n        throw Error(\"decrypt was provided, but it is not a function!\");\n      }\n      this.encrypt = makeExternalFunctionSafe(\n        this.options.encrypt,\n        (a) => `Error while invoking encrypt function. Supplied args: ${a}`,\n      );\n      this.decrypt = makeExternalFunctionSafe(\n        this.options.decrypt,\n        (a) =>\n          `Error while invoking decrypt function. Is the data really encrypted? Supplied args: ${a}`,\n      );\n\n      this._names = {\n        objectStoreName: \"LID\",\n        lokiKeyName: \"lk_____________\", // some padding to give it roughly the same length as <tablename>.ck.<number>, so that is is indistinguishable\n        chunk: \"ck\",\n        metadata: \"md___\", // padding for the same reason as lokiKeyName\n      };\n    } else {\n      this.encrypt = doNothing;\n      this.decrypt = doNothing;\n      this._names = {\n        objectStoreName: \"LokiIncrementalData\",\n        lokiKeyName: \"loki\",\n        chunk: \"chunk\",\n        metadata: \"metadata\",\n      };\n    }\n\n    if (!(this.megachunkCount >= 4 && this.megachunkCount % 2 === 0)) {\n      throw new Error(\"megachunkCount must be >=4 and divisible by 2\");\n    }\n  }\n\n  // chunkId - index of the data chunk - e.g. chunk 0 will be lokiIds 0-99\n  _getChunk(collection, chunkId) {\n    // 0-99, 100-199, etc.\n    const minId = chunkId * this.chunkSize;\n    const maxId = minId + this.chunkSize - 1;\n\n    // use idIndex to find first collection.data position within the $loki range\n    collection.ensureId();\n    const idIndex = collection.idIndex;\n\n    let firstDataPosition = null;\n\n    let max = idIndex.length - 1;\n    let min = 0;\n    let mid;\n\n    while (idIndex[min] < idIndex[max]) {\n      mid = (min + max) >> 1;\n\n      if (idIndex[mid] < minId) {\n        min = mid + 1;\n      } else {\n        max = mid;\n      }\n    }\n\n    if (max === min && idIndex[min] >= minId && idIndex[min] <= maxId) {\n      firstDataPosition = min;\n    }\n\n    if (firstDataPosition === null) {\n      // no elements in this chunk\n      return [];\n    }\n\n    // find last position\n    // if loki IDs are contiguous (no removed elements), last position will be first + chunk - 1\n    // (and we look back in case there are missing pieces)\n    // TODO: Binary search (not as important as first position, worst case scanario is only chunkSize steps)\n    let lastDataPosition = null;\n    for (\n      let i = firstDataPosition + this.chunkSize - 1;\n      i >= firstDataPosition;\n      i--\n    ) {\n      if (idIndex[i] <= maxId) {\n        lastDataPosition = i;\n        break;\n      }\n    }\n\n    // verify\n    const firstElement = collection.data[firstDataPosition];\n    if (\n      !(\n        firstElement &&\n        firstElement.$loki >= minId &&\n        firstElement.$loki <= maxId\n      )\n    ) {\n      throw new Error(\"broken invariant firstelement\");\n    }\n\n    const lastElement = collection.data[lastDataPosition];\n    if (\n      !(lastElement && lastElement.$loki >= minId && lastElement.$loki <= maxId)\n    ) {\n      throw new Error(\"broken invariant lastElement\");\n    }\n\n    // this will have *up to* 'this.chunkSize' elements (might have less, because $loki ids\n    // will have holes when data is deleted)\n    const chunkData = collection.data.slice(\n      firstDataPosition,\n      lastDataPosition + 1,\n    );\n\n    if (chunkData.length > this.chunkSize) {\n      throw new Error(\"broken invariant - chunk size\");\n    }\n\n    return chunkData;\n  }\n\n  /**\n   * Incrementally saves the database to IndexedDB\n   *\n   * @example\n   * var idbAdapter = new IncrementalIndexedDBAdapter();\n   * var db = new loki('test', { adapter: idbAdapter });\n   * var coll = db.addCollection('testColl');\n   * coll.insert({test: 'val'});\n   * db.saveDatabase();\n   *\n   * @param {string} dbname - the name to give the serialized database\n   * @param {function} getLokiCopy - returns copy of the Loki database\n   * @param {function} callback - (Optional) callback passed obj.success with true or false\n   * @memberof IncrementalIndexedDBAdapter\n   */\n  saveDatabase(dbname, getLokiCopy, callback) {\n    const that = this;\n\n    if (!this.idb) {\n      this._initializeIDB(dbname, callback, () => {\n        that.saveDatabase(dbname, getLokiCopy, callback);\n      });\n      return;\n    }\n\n    if (this.operationInProgress) {\n      throw new Error(\n        \"Error while saving to database - another operation is already in progress. Please use throttledSaves=true option on Loki object\",\n      );\n    }\n    this.operationInProgress = true;\n\n    DEBUG && console.log(\"saveDatabase - begin\");\n    DEBUG && console.time(\"saveDatabase\");\n    function finish(e) {\n      DEBUG && e && console.error(e);\n      DEBUG && console.timeEnd(\"saveDatabase\");\n      that.operationInProgress = false;\n      callback(e);\n    }\n\n    // try..catch is required, e.g.:\n    // InvalidStateError: Failed to execute 'transaction' on 'IDBDatabase': The database connection is closing.\n    // (this may happen if another tab has called deleteDatabase)\n    try {\n      let updatePrevVersionIds = () => {\n        console.error(\n          \"Unexpected successful tx - cannot update previous version ids\",\n        );\n      };\n      let didOverwrite = false;\n\n      const tx = this.idb.transaction(\n        [that.idbActualLokiObjectStoreName],\n        \"readwrite\",\n      );\n      tx.oncomplete = () => {\n        updatePrevVersionIds();\n        finish();\n        if (didOverwrite && that.options.onDidOverwrite) {\n          that.options.onDidOverwrite();\n        }\n      };\n\n      tx.onerror = (e) => {\n        finish(e);\n      };\n\n      tx.onabort = (e) => {\n        finish(e);\n      };\n\n      const store = tx.objectStore(that.idbActualLokiObjectStoreName);\n\n      const performSave = (maxChunkIds) => {\n        try {\n          const incremental = !maxChunkIds;\n          const chunkInfo = that._putInChunks(\n            store,\n            getLokiCopy(),\n            incremental,\n            maxChunkIds,\n          );\n          // Update last seen version IDs, but only after the transaction is successful\n          updatePrevVersionIds = () => {\n            that._prevLokiVersionId = chunkInfo.lokiVersionId;\n            chunkInfo.collectionVersionIds.forEach(({ name, versionId }) => {\n              that._prevCollectionVersionIds[name] = versionId;\n            });\n          };\n          tx.commit && tx.commit();\n        } catch (error) {\n          console.error(\"idb performSave failed: \", error);\n          tx.abort();\n        }\n      };\n\n      // Incrementally saving changed chunks breaks down if there is more than one writer to IDB\n      // (multiple tabs of the same web app), leading to data corruption. To fix that, we save all\n      // metadata chunks (loki + collections) with a unique ID on each save and remember it. Before\n      // the subsequent save, we read loki from IDB to check if its version ID changed. If not, we're\n      // guaranteed that persisted DB is consistent with our diff. Otherwise, we fall back to the slow\n      // path and overwrite *all* database chunks with our version. Both reading and writing must\n      // happen in the same IDB transaction for this to work.\n      // TODO: We can optimize the slow path by fetching collection metadata chunks and comparing their\n      // version IDs with those last seen by us. Since any change in collection data requires a metadata\n      // chunk save, we're guaranteed that if the IDs match, we don't need to overwrite chukns of this collection\n      const getAllKeysThenSave = () => {\n        // NOTE: We must fetch all keys to protect against a case where another tab has wrote more\n        // chunks whan we did -- if so, we must delete them.\n        idbReq(\n          store.getAllKeys(),\n          ({ target }) => {\n            const maxChunkIds = getMaxChunkIds(target.result, that.keyResolver);\n            performSave(maxChunkIds);\n          },\n          (e) => {\n            console.error(\"Getting all keys failed: \", e);\n            tx.abort();\n          },\n        );\n      };\n\n      const getLokiThenSave = () => {\n        idbReq(\n          store.get(that.keyResolver.actualLokiKey),\n          ({ target }) => {\n            if (\n              lokiChunkVersionId(target.result, that.decrypt) ===\n              that._prevLokiVersionId\n            ) {\n              performSave();\n            } else {\n              DEBUG &&\n                console.warn(\n                  \"Another writer changed Loki IDB, using slow path...\",\n                );\n              didOverwrite = true;\n              getAllKeysThenSave();\n            }\n          },\n          (e) => {\n            console.error(\"Getting loki chunk failed: \", e);\n            tx.abort();\n          },\n        );\n      };\n\n      getLokiThenSave();\n    } catch (error) {\n      finish(error);\n    }\n  }\n\n  _putInChunks(idbStore, loki, incremental, maxChunkIds) {\n    const that = this;\n    const collectionVersionIds = [];\n    let savedSize = 0;\n\n    const prepareCollection = (collection, i) => {\n      // Find dirty chunk ids\n      const dirtyChunks = new Set();\n      incremental &&\n        collection.dirtyIds.forEach((lokiId) => {\n          const chunkId = (lokiId / that.chunkSize) | 0;\n          dirtyChunks.add(chunkId);\n        });\n      collection.dirtyIds = [];\n\n      // Serialize chunks to save\n      const prepareChunk = (chunkId) => {\n        let chunkData = that._getChunk(collection, chunkId);\n        if (that.options.serializeChunk) {\n          chunkData = that.options.serializeChunk(collection.name, chunkData);\n        }\n        // we must stringify now, because IDB is asynchronous, and underlying objects are mutable\n        // In general, it's also faster to stringify, because we need serialization anyway, and\n        // JSON.stringify is much better optimized than IDB's structured clone\n        chunkData = that.encrypt(JSON.stringify(chunkData));\n        savedSize += chunkData.length;\n        DEBUG &&\n          incremental &&\n          console.log(`Saving: ${collection.name}.chunk.${chunkId}`);\n        idbStore.put({\n          key: that.keyResolver.getOrGenerateCiphertextCollectionChunkKey(\n            collection.name,\n            chunkId,\n          ),\n          value: chunkData,\n        });\n      };\n      if (incremental) {\n        dirtyChunks.forEach(prepareChunk);\n      } else {\n        // add all chunks\n        const maxChunkId = (collection.maxId / that.chunkSize) | 0;\n        for (let j = 0; j <= maxChunkId; j += 1) {\n          prepareChunk(j);\n        }\n\n        // delete chunks with larger ids than what we have\n        // NOTE: we don't have to delete metadata chunks as they will be absent from loki anyway\n        // NOTE: failures are silently ignored, so we don't have to worry about holes\n        const persistedMaxChunkId = maxChunkIds[collection.name] || 0;\n        for (let k = maxChunkId + 1; k <= persistedMaxChunkId; k += 1) {\n          const deletedChunkName =\n            that.keyResolver.getOrGenerateCiphertextCollectionChunkKey(\n              collection.name,\n              k,\n            );\n          idbStore.delete(deletedChunkName);\n          DEBUG && console.warn(`Deleted chunk: ${deletedChunkName}`);\n        }\n      }\n\n      // save collection metadata as separate chunk (but only if changed)\n      if (collection.dirty || dirtyChunks.size || !incremental) {\n        collection.idIndex = []; // this is recreated lazily\n        collection.data = [];\n        collection.idbVersionId = randomVersionId();\n        collectionVersionIds.push({\n          name: collection.name,\n          versionId: collection.idbVersionId,\n        });\n\n        const metadataChunk = that.encrypt(JSON.stringify(collection));\n        savedSize += metadataChunk.length;\n        DEBUG &&\n          incremental &&\n          console.log(`Saving: ${collection.name}.metadata`);\n        idbStore.put({\n          key: that.keyResolver.getOrGenerateCiphertextCollectionMetadataKey(\n            collection.name,\n          ),\n          value: metadataChunk,\n        });\n      }\n\n      // leave only names in the loki chunk\n      loki.collections[i] = { name: collection.name };\n    };\n    loki.collections.forEach(prepareCollection);\n\n    loki.idbVersionId = randomVersionId();\n    const serializedMetadata = that.encrypt(JSON.stringify(loki));\n    savedSize += serializedMetadata.length;\n\n    DEBUG && incremental && console.log(\"Saving: loki\");\n    idbStore.put({\n      key: that.keyResolver.actualLokiKey,\n      value: serializedMetadata,\n    });\n\n    DEBUG && console.log(`saved size: ${savedSize}`);\n    return {\n      lokiVersionId: loki.idbVersionId,\n      collectionVersionIds,\n    };\n  }\n\n  /**\n   * Retrieves a serialized db string from the catalog.\n   *\n   * @example\n   * // LOAD\n   * var idbAdapter = new IncrementalIndexedDBAdapter();\n   * var db = new loki('test', { adapter: idbAdapter });\n   * db.loadDatabase(function(result) {\n   *   console.log('done');\n   * });\n   *\n   * @param {string} dbname - the name of the database to retrieve.\n   * @param {function} callback - callback should accept string param containing serialized db string.\n   * @memberof IncrementalIndexedDBAdapter\n   */\n  loadDatabase(dbname, callback) {\n    const that = this;\n\n    if (this.operationInProgress) {\n      throw new Error(\n        \"Error while loading database - another operation is already in progress. Please use throttledSaves=true option on Loki object\",\n      );\n    }\n\n    this.operationInProgress = true;\n\n    DEBUG && console.log(\"loadDatabase - begin\");\n    DEBUG && console.time(\"loadDatabase\");\n\n    const finish = (value) => {\n      DEBUG && console.timeEnd(\"loadDatabase\");\n      that.operationInProgress = false;\n      callback(value);\n    };\n\n    this._getAllChunks(dbname, (chunks) => {\n      try {\n        if (!Array.isArray(chunks)) {\n          throw chunks; // we have an error\n        }\n\n        if (!chunks.length) {\n          return finish(null);\n        }\n\n        DEBUG && console.log(\"Found chunks:\", chunks.length);\n\n        // repack chunks into a map\n        chunks = chunksToMap(chunks, that.keyResolver);\n        const loki = chunks.loki;\n        chunks.loki = null; // gc\n\n        // populate collections with data\n        populateLoki(loki, chunks.chunkMap);\n        chunks = null; // gc\n\n        // remember previous version IDs\n        that._prevLokiVersionId = loki.idbVersionId || null;\n        that._prevCollectionVersionIds = {};\n        loki.collections.forEach(({ name, idbVersionId }) => {\n          that._prevCollectionVersionIds[name] = idbVersionId || null;\n        });\n\n        return finish(loki);\n      } catch (error) {\n        that._prevLokiVersionId = null;\n        that._prevCollectionVersionIds = {};\n        return finish(error);\n      }\n    });\n  }\n\n  _initializeIDB(dbname, onError, onSuccess) {\n    const that = this;\n    DEBUG && console.log(\"initializing idb\");\n\n    if (this.idbInitInProgress) {\n      throw new Error(\n        \"Cannot open IndexedDB because open is already in progress\",\n      );\n    }\n    this.idbInitInProgress = true;\n\n    const openRequest = indexedDB.open(dbname, 1);\n\n    openRequest.onupgradeneeded = ({ target, oldVersion }) => {\n      const db = target.result;\n      DEBUG && console.log(`onupgradeneeded, old version: ${oldVersion}`);\n\n      if (oldVersion < 1) {\n        // Version 1 - Initial - Create database\n        db.createObjectStore(that.encrypt(that._names.objectStoreName), {\n          keyPath: \"key\",\n        });\n      } else {\n        // Unknown version\n        throw new Error(\n          `Invalid old version ${oldVersion} for IndexedDB upgrade`,\n        );\n      }\n    };\n\n    openRequest.onsuccess = ({ target }) => {\n      that.idbInitInProgress = false;\n      const db = target.result;\n      that.idb = db;\n      that.idbActualLokiObjectStoreName = findIdbActualLokiObjectStoreName(\n        db,\n        that._names.objectStoreName,\n        that.decrypt,\n      );\n      if (!that.idbActualLokiObjectStoreName) {\n        onError(\n          new Error(\n            `Missing IndexedDB objectStore: ${that._names.objectStoreName}${\n              that.decrypt ? \" (searched using decrypt function)\" : \"\"\n            }`,\n          ),\n        );\n        // Attempt to recover (after reload) by deleting database, since it's damaged anyway\n        that.deleteDatabase(dbname);\n        return;\n      }\n\n      const tx = that.idb.transaction(\n        [that.idbActualLokiObjectStoreName],\n        \"readonly\",\n      );\n      const store = tx.objectStore(that.idbActualLokiObjectStoreName);\n      extractkeyResolver(store, that._names, that.encrypt, that.decrypt)\n        .then((keyResolver) => {\n          that.keyResolver = keyResolver;\n\n          DEBUG && console.log(\"init success\");\n\n          db.onversionchange = (versionChangeEvent) => {\n            // Ignore if database was deleted and recreated in the meantime\n            if (that.idb !== db) {\n              return;\n            }\n\n            DEBUG && console.log(\"IDB version change\", versionChangeEvent);\n            // This function will be called if another connection changed DB version\n            // (Most likely database was deleted from another browser tab, unless there's a new version\n            // of this adapter, or someone makes a connection to IDB outside of this adapter)\n            // We must close the database to avoid blocking concurrent deletes.\n            // The database will be unusable after this. Be sure to supply `onversionchange` option\n            // to force logout\n            that.idb.close();\n            that.idb = null;\n            if (that.options.onversionchange) {\n              that.options.onversionchange(versionChangeEvent);\n            }\n          };\n\n          onSuccess();\n        })\n        .catch((e) => {\n          console.error(\"Error while retrieving actual IDB lokiKeyName\", e);\n          throw e;\n        });\n    };\n\n    openRequest.onblocked = (e) => {\n      console.error(\"IndexedDB open is blocked\", e);\n      onError(new Error(\"IndexedDB open is blocked by open connection\"));\n    };\n\n    openRequest.onerror = (e) => {\n      that.idbInitInProgress = false;\n      console.error(\"IndexedDB open error\", e);\n      onError(e);\n    };\n  }\n\n  _getAllChunks(dbname, callback) {\n    const that = this;\n    if (!this.idb) {\n      this._initializeIDB(dbname, callback, () => {\n        that._getAllChunks(dbname, callback);\n      });\n      return;\n    }\n\n    const tx = this.idb.transaction(\n      [that.idbActualLokiObjectStoreName],\n      \"readonly\",\n    );\n    const store = tx.objectStore(that.idbActualLokiObjectStoreName);\n\n    // If there are a lot of chunks (>100), don't request them all in one go, but in multiple\n    // \"megachunks\" (chunks of chunks). This improves concurrency, as main thread is already busy\n    // while IDB process is still fetching data. Details: https://github.com/techfort/LokiJS/pull/874\n    function getMegachunks(keys) {\n      const megachunkCount = that.megachunkCount;\n      const keyRanges = createKeyRanges(keys, megachunkCount);\n\n      const allChunks = [];\n      let megachunksReceived = 0;\n\n      function processMegachunk({ target }, megachunkIndex, keyRange) {\n        // var debugMsg = 'processing chunk ' + megachunkIndex + ' (' + keyRange.lower + ' -- ' + keyRange.upper + ')'\n        // DEBUG && console.time(debugMsg);\n        const megachunk = target.result;\n        megachunk.forEach((chunk, i) => {\n          parseChunk(\n            chunk,\n            that.deserializeChunk,\n            that.keyResolver,\n            that.decrypt,\n          );\n          allChunks.push(chunk);\n          megachunk[i] = null; // gc\n        });\n        // DEBUG && console.timeEnd(debugMsg);\n\n        megachunksReceived += 1;\n        if (megachunksReceived === megachunkCount) {\n          callback(allChunks);\n        }\n      }\n\n      // Stagger megachunk requests - first one half, then request the second when first one comes\n      // back. This further improves concurrency.\n      function requestMegachunk(index) {\n        const keyRange = keyRanges[index];\n        idbReq(\n          store.getAll(keyRange),\n          (e) => {\n            if (index < megachunkCount / 2) {\n              requestMegachunk(index + megachunkCount / 2);\n            }\n\n            processMegachunk(e, index, keyRange);\n          },\n          (e) => {\n            callback(e);\n          },\n        );\n      }\n\n      for (let i = 0; i < megachunkCount / 2; i += 1) {\n        requestMegachunk(i);\n      }\n    }\n\n    function getAllChunks() {\n      idbReq(\n        store.getAll(),\n        ({ target }) => {\n          const allChunks = target.result;\n          allChunks.forEach((chunk) => {\n            parseChunk(\n              chunk,\n              that.deserializeChunk,\n              that.keyResolver,\n              that.decrypt,\n            );\n          });\n          callback(allChunks);\n        },\n        (e) => {\n          callback(e);\n        },\n      );\n    }\n\n    function getAllKeys() {\n      idbReq(\n        store.getAllKeys(),\n        ({ target }) => {\n          const keys = target.result.sort();\n          if (keys.length > 100) {\n            getMegachunks(keys);\n          } else {\n            getAllChunks();\n          }\n        },\n        (e) => {\n          callback(e);\n        },\n      );\n\n      if (that.options.onFetchStart) {\n        that.options.onFetchStart();\n      }\n    }\n\n    getAllKeys();\n  }\n\n  /**\n   * Deletes a database from IndexedDB\n   *\n   * @example\n   * // DELETE DATABASE\n   * // delete 'finance'/'test' value from catalog\n   * idbAdapter.deleteDatabase('test', function {\n   *   // database deleted\n   * });\n   *\n   * @param {string} dbname - the name of the database to delete from IDB\n   * @param {function=} callback - (Optional) executed on database delete\n   * @memberof IncrementalIndexedDBAdapter\n   */\n  deleteDatabase(dbname, callback) {\n    if (this.operationInProgress) {\n      throw new Error(\n        \"Error while deleting database - another operation is already in progress. Please use throttledSaves=true option on Loki object\",\n      );\n    }\n\n    this.operationInProgress = true;\n\n    const that = this;\n    DEBUG && console.log(\"deleteDatabase - begin\");\n    DEBUG && console.time(\"deleteDatabase\");\n\n    this._prevLokiVersionId = null;\n    this._prevCollectionVersionIds = {};\n\n    if (this.idb) {\n      this.idb.close();\n      this.idb = null;\n    }\n\n    const request = indexedDB.deleteDatabase(dbname);\n\n    request.onsuccess = () => {\n      that.operationInProgress = false;\n      DEBUG && console.timeEnd(\"deleteDatabase\");\n      callback({ success: true });\n    };\n\n    request.onerror = (e) => {\n      that.operationInProgress = false;\n      console.error(\"Error while deleting database\", e);\n      callback({ success: false });\n    };\n\n    request.onblocked = (e) => {\n      // We can't call callback with failure status, because this will be called even if we\n      // succeed in just a moment\n      console.error(\n        \"Deleting database failed because it's blocked by another connection\",\n        e,\n      );\n    };\n  }\n}\n\n// gets current largest chunk ID for each collection\nfunction getMaxChunkIds(allCiphertextKeys, keyResolver) {\n  const maxChunkIds = {};\n\n  allCiphertextKeys.forEach((ciphertextKey) => {\n    // table.chunk.2317\n    if (keyResolver.isChunkKey(ciphertextKey)) {\n      const collection =\n        keyResolver.getCollectionNameForCiphertextChunkKey(ciphertextKey);\n      const chunkId = extractChunkIdFromChunkKey(ciphertextKey) || 0;\n      const currentMax = maxChunkIds[collection];\n\n      if (!currentMax || chunkId > currentMax) {\n        maxChunkIds[collection] = chunkId;\n      }\n    }\n  });\n  return maxChunkIds;\n}\n\nfunction lokiChunkVersionId(chunk, decryptFn) {\n  try {\n    if (chunk) {\n      const loki = JSON.parse(decryptFn(chunk.value));\n      return loki.idbVersionId || null;\n    } else {\n      return null;\n    }\n  } catch (e) {\n    console.error(\"Error while parsing loki chunk\", e);\n    return null;\n  }\n}\n\nfunction chunksToMap(chunks, keyResolver) {\n  let loki;\n  const chunkMap = {};\n\n  sortChunksInPlace(chunks, keyResolver);\n\n  chunks.forEach((object) => {\n    const key = object.key;\n    const value = object.value;\n    if (keyResolver.isLokiKey(key)) {\n      loki = value;\n      return;\n    } else {\n      if (keyResolver.isChunkKey(key)) {\n        const colName = keyResolver.getCollectionNameForCiphertextChunkKey(key);\n        if (chunkMap[colName]) {\n          chunkMap[colName].dataChunks.push(value);\n        } else {\n          chunkMap[colName] = {\n            metadata: null,\n            dataChunks: [value],\n          };\n        }\n        return;\n      }\n      if (keyResolver.isMetadataKey(key)) {\n        const name = keyResolver.getCollectionNameForMetadataKey(key);\n        if (chunkMap[name]) {\n          chunkMap[name].metadata = value;\n        } else {\n          chunkMap[name] = { metadata: value, dataChunks: [] };\n        }\n        return;\n      }\n    }\n\n    console.error(`Unknown chunk ${key}`);\n    throw new Error(\"Corrupted database - unknown chunk found\");\n  });\n\n  if (!loki) {\n    throw new Error(\"Corrupted database - missing database metadata\");\n  }\n\n  return { loki, chunkMap };\n}\n\nfunction populateLoki({ collections }, chunkMap) {\n  collections.forEach(function populateCollection(collectionStub, i) {\n    const chunkCollection = chunkMap[collectionStub.name];\n    if (chunkCollection) {\n      if (!chunkCollection.metadata) {\n        throw new Error(\n          `Corrupted database - missing metadata chunk for ${collectionStub.name}`,\n        );\n      }\n      const collection = chunkCollection.metadata;\n      chunkCollection.metadata = null;\n\n      collections[i] = collection;\n\n      const dataChunks = chunkCollection.dataChunks;\n      dataChunks.forEach(function populateChunk(chunk, i) {\n        chunk.forEach((doc) => {\n          collection.data.push(doc);\n        });\n        dataChunks[i] = null;\n      });\n    }\n  });\n}\n\nfunction parseChunk(chunk, deserializeChunk, keyResolver, decryptFn) {\n  chunk.value = JSON.parse(decryptFn(chunk.value));\n  if (deserializeChunk) {\n    if (keyResolver.isChunkKey(chunk.key)) {\n      const collectionName = keyResolver.getCollectionNameForCiphertextChunkKey(\n        chunk.key,\n      );\n      chunk.value = deserializeChunk(collectionName, chunk.value);\n    }\n  }\n}\n\nfunction randomVersionId() {\n  // Appears to have enough entropy for chunk version IDs\n  // (Only has to be different than enough of its own previous versions that there's no writer\n  // that thinks a new version is the same as an earlier one, not globally unique)\n  return Math.random().toString(36).substring(2);\n}\n\nfunction _getSortKey(object, keyResolver) {\n  const key = object.key;\n  if (keyResolver.isChunkKey(key)) {\n    return extractChunkIdFromChunkKey(key);\n  }\n\n  return -1; // consistent type must be returned\n}\n\nfunction sortChunksInPlace(chunks, keyResolver) {\n  // sort chunks in place to load data in the right order (ascending loki ids)\n  // on both Safari and Chrome, we'll get chunks in order like this: 0, 1, 10, 100...\n  chunks.sort((a, b) => {\n    const aKey = _getSortKey(a, keyResolver);\n    const bKey = _getSortKey(b, keyResolver);\n    if (aKey < bKey) return -1;\n    if (aKey > bKey) return 1;\n    return 0;\n  });\n}\n\nfunction createKeyRanges(keys, count) {\n  const countPerRange = Math.floor(keys.length / count);\n  const keyRanges = [];\n  let minKey;\n  let maxKey;\n  for (let i = 0; i < count; i += 1) {\n    minKey = keys[countPerRange * i];\n    maxKey = keys[countPerRange * (i + 1)];\n    if (i === 0) {\n      // ... < maxKey\n      keyRanges.push(IDBKeyRange.upperBound(maxKey, true));\n    } else if (i === count - 1) {\n      // >= minKey\n      keyRanges.push(IDBKeyRange.lowerBound(minKey));\n    } else {\n      // >= minKey && < maxKey\n      keyRanges.push(IDBKeyRange.bound(minKey, maxKey, false, true));\n    }\n  }\n  return keyRanges;\n}\n\nfunction idbReq(request, onsuccess, onerror) {\n  request.onsuccess = (e) => {\n    try {\n      return onsuccess(e);\n    } catch (error) {\n      onerror(error);\n    }\n  };\n  request.onerror = onerror;\n  return request;\n}\n\nfunction findIdbActualLokiObjectStoreName(\n  { objectStoreNames },\n  decryptedObjectStoreName,\n  decryptFn,\n) {\n  const domStringList = objectStoreNames;\n  for (let i = 0; i < domStringList.length; i++) {\n    if (decryptFn(domStringList[i]) === decryptedObjectStoreName) {\n      return domStringList[i];\n    }\n  }\n  return null;\n}\n\nfunction isFunction(fn) {\n  return typeof fn === \"function\";\n}\n\nfunction doNothing(x) {\n  return x;\n}\n\nfunction makeExternalFunctionSafe(fn, erroMessageGenerator) {\n  return function (...args) {\n    try {\n      return fn.apply(this, args);\n    } catch (e) {\n      console.error(erroMessageGenerator(args), e);\n      throw e;\n    }\n  };\n}\n\nfunction getChunkKeyWithoutChunkId(key) {\n  const matchKeyWithoutChunkId = key.match(/^(.+)\\.\\d+$/);\n  if (matchKeyWithoutChunkId === null) {\n    return null;\n  }\n  return matchKeyWithoutChunkId[1];\n}\n\nfunction extractChunkIdFromChunkKey(key) {\n  const chunkId = key.match(/^.+\\.(\\d+)$/);\n  if (chunkId === null) {\n    return null;\n  }\n  return parseInt(chunkId[1], 10);\n}\n\nfunction isCiphertextChunkKey(ciphertextChunkKey, _names, decryptFn) {\n  const ciphertextChunkKeyWithoutChunkId =\n    getChunkKeyWithoutChunkId(ciphertextChunkKey);\n  if (!ciphertextChunkKeyWithoutChunkId) {\n    return false;\n  }\n  const plaintextChunkKeyWithoutChunkId = decryptFn(\n    ciphertextChunkKeyWithoutChunkId,\n  );\n  return isPlaintextChunkKeyWithoutChunkId(\n    plaintextChunkKeyWithoutChunkId,\n    _names,\n  );\n}\n\nfunction isPlaintextChunkKeyWithoutChunkId(\n  plaintextChunkKeyWithoutChunkId,\n  { chunk },\n) {\n  return (\n    plaintextChunkKeyWithoutChunkId.length -\n      plaintextChunkKeyWithoutChunkId.lastIndexOf(`.${chunk}`) -\n      `.${chunk}`.length ===\n    0\n  );\n}\n\nfunction extractCollectionNameFromPlaintextChunkKey(plaintextChunkKey, _names) {\n  const plaintextChunkKeyWithoutChunkId =\n    getChunkKeyWithoutChunkId(plaintextChunkKey);\n  if (!plaintextChunkKeyWithoutChunkId === null) {\n    return null;\n  }\n  return extractCollectionNameFromPlaintextChunkKeyWithoutChunkId(\n    plaintextChunkKeyWithoutChunkId,\n    _names,\n  );\n}\n\nfunction extractCollectionNameFromPlaintextChunkKeyWithoutChunkId(\n  plaintextChunkKeyWithoutChunkId,\n  { chunk },\n) {\n  const lastIndexOfChunkKeyName = plaintextChunkKeyWithoutChunkId.lastIndexOf(\n    `.${chunk}`,\n  );\n  if (lastIndexOfChunkKeyName === -1) {\n    throw new Error(\n      `Malformed chunk key without chunk id: ${plaintextChunkKeyWithoutChunkId}. Could not find chunk term (${chunk})`,\n    );\n  }\n  return plaintextChunkKeyWithoutChunkId.substring(0, lastIndexOfChunkKeyName);\n}\n\nfunction isPlaintextMetadataKey(plaintextMetadataKey, { metadata }) {\n  return (\n    plaintextMetadataKey.length -\n      plaintextMetadataKey.lastIndexOf(`.${metadata}`) -\n      `.${metadata}`.length ===\n    0\n  );\n}\n\nfunction extractCollectionNameFromPlaintextMetadataKey(\n  plaintextMetadataKey,\n  { metadata },\n) {\n  return plaintextMetadataKey.substring(\n    0,\n    plaintextMetadataKey.lastIndexOf(`.${metadata}`),\n  );\n}\n\nfunction extractkeyResolver(store, _names, encryptFn, decryptFn) {\n  const isEncriptionNotEnabled = !encryptFn;\n\n  if (isEncriptionNotEnabled) {\n    return new Promise((resolve) => {\n      resolve({\n        actualLokiKey: _names.lokiKeyName,\n        isLokiKey(plaintextKey) {\n          return plaintextKey === _names.lokiKeyName;\n        },\n        isMetadataKey(plaintextKey) {\n          return isPlaintextMetadataKey(plaintextKey, _names);\n        },\n        isChunkKey(plaintextKey) {\n          const plaintextChunkKeyWithoutChunkId =\n            getChunkKeyWithoutChunkId(plaintextKey);\n          if (!plaintextChunkKeyWithoutChunkId) {\n            return false;\n          }\n          return isPlaintextChunkKeyWithoutChunkId(\n            plaintextChunkKeyWithoutChunkId,\n            _names,\n          );\n        },\n        getCollectionNameForMetadataKey(plaintextKey) {\n          return extractCollectionNameFromPlaintextMetadataKey(\n            plaintextKey,\n            _names,\n          );\n        },\n        getOrGenerateCiphertextCollectionMetadataKey(collectionName) {\n          return `${collectionName}.${_names.metadata}`;\n        },\n        getCollectionNameForCiphertextChunkKey(key) {\n          return extractCollectionNameFromPlaintextChunkKey(key, _names);\n        },\n        getOrGenerateCiphertextCollectionChunkKey(collectionName, chunkId) {\n          return `${collectionName}.${_names.chunk}.${chunkId}`;\n        },\n      });\n    });\n  }\n\n  return new Promise((resolve, reject) => {\n    idbReq(\n      store.getAllKeys(),\n      ({ target }) => {\n        const keys = target.result;\n\n        let ciphertextLokiKey = null;\n        const plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId = {\n          /* plaintextCollectionName: ciphertextChunkKeyWithoutChunkId */\n        };\n        const keyResolver = {\n          ciphertextCollectionMetadataKeys: {\n            /* collectioName: ciphertextCollectionNameAndMetadataForThisCollection */\n          },\n          metadataCiphertextToCollectionName: {\n            /* ciphertextCollectionNameAndMetadataForThisCollection: collectionName */\n          },\n\n          chunkCiphertextToCollectionName: {\n            /* ciphertextCollectionNameAndChunkForThisCollection: collectionName */\n          },\n        };\n        if (keys.length === 0) {\n          // newly created database, we generate lokiKeyName and the others will be generated on-the-fly as needed\n          ciphertextLokiKey = encryptFn(_names.lokiKeyName);\n        } else {\n          for (let i = 0; i < keys.length; i++) {\n            const key = keys[i];\n            if (isCiphertextChunkKey(key, _names, decryptFn)) {\n              const ciphertextChunkKeyWithoutChunkId =\n                getChunkKeyWithoutChunkId(key);\n              if (!ciphertextChunkKeyWithoutChunkId) {\n                throw Error(\n                  `Could not extract collection name from ciphertext chunk key: ${key}. It did not match the [ciphertext].[chunkId] pattern.`,\n                );\n              }\n              const plaintextCollectionName =\n                extractCollectionNameFromPlaintextChunkKeyWithoutChunkId(\n                  decryptFn(ciphertextChunkKeyWithoutChunkId),\n                  _names,\n                );\n              plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId[\n                plaintextCollectionName\n              ] = ciphertextChunkKeyWithoutChunkId;\n              keyResolver.chunkCiphertextToCollectionName[\n                ciphertextChunkKeyWithoutChunkId\n              ] = plaintextCollectionName;\n            } else {\n              const plaintextKey = decryptFn(key);\n              if (plaintextKey === _names.lokiKeyName) {\n                ciphertextLokiKey = key;\n              } else if (isPlaintextMetadataKey(plaintextKey, _names)) {\n                const collectionName =\n                  extractCollectionNameFromPlaintextMetadataKey(\n                    plaintextKey,\n                    _names,\n                  );\n                keyResolver.ciphertextCollectionMetadataKeys[collectionName] =\n                  key;\n                keyResolver.metadataCiphertextToCollectionName[key] =\n                  collectionName;\n              } else {\n                // todo maybe just warn\n                throw Error(\n                  `Error while loading keys from IDB: Unknown or malformed key (not chunk, loki or meta): ${key} - Plaintext: ${plaintextKey}`,\n                );\n              }\n            }\n          }\n        }\n        if (ciphertextLokiKey) {\n          resolve({\n            actualLokiKey: ciphertextLokiKey,\n            metadataCiphertextToCollectionName:\n              keyResolver.metadataCiphertextToCollectionName,\n            isLokiKey(ciphertextKey) {\n              return ciphertextKey === ciphertextLokiKey;\n            },\n            isMetadataKey(ciphertextKey) {\n              return !!keyResolver.metadataCiphertextToCollectionName[\n                ciphertextKey\n              ];\n            },\n            isChunkKey(ciphertextKey) {\n              return isCiphertextChunkKey(ciphertextKey, _names, decryptFn);\n            },\n            getCollectionNameForMetadataKey(ciphertextKey) {\n              return keyResolver.metadataCiphertextToCollectionName[\n                ciphertextKey\n              ];\n            },\n            getOrGenerateCiphertextCollectionMetadataKey(collectionName) {\n              if (\n                !keyResolver.ciphertextCollectionMetadataKeys[collectionName]\n              ) {\n                const metadataCiphertext = encryptFn(\n                  `${collectionName}.${_names.metadata}`,\n                );\n                keyResolver.ciphertextCollectionMetadataKeys[collectionName] =\n                  metadataCiphertext;\n                keyResolver.metadataCiphertextToCollectionName[\n                  metadataCiphertext\n                ] = collectionName;\n              }\n              return keyResolver.ciphertextCollectionMetadataKeys[\n                collectionName\n              ];\n            },\n            getCollectionNameForCiphertextChunkKey(key) {\n              const keyWithoutChunkId = getChunkKeyWithoutChunkId(key);\n              return keyResolver.chunkCiphertextToCollectionName[\n                keyWithoutChunkId\n              ];\n            },\n            getOrGenerateCiphertextCollectionChunkKey(collectionName, chunkId) {\n              if (\n                !plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId[\n                  collectionName\n                ]\n              ) {\n                const ciphertextCollectionNameAndChunk = encryptFn(\n                  `${collectionName}.${_names.chunk}`,\n                );\n                plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId[\n                  collectionName\n                ] = ciphertextCollectionNameAndChunk;\n                keyResolver.chunkCiphertextToCollectionName[\n                  ciphertextCollectionNameAndChunk\n                ] = collectionName;\n              }\n              return `${plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId[collectionName]}.${chunkId}`;\n            },\n          });\n        } else {\n          reject({\n            message: `Failed to resolve keyResolver. DB was not empty, a loki key with name '${_names.lokiKeyName}' is expected but was not found.`,\n          });\n        }\n      },\n      (e) => {\n        reject({ message: \"Error on IDB getAllKeys request\", e });\n      },\n    );\n  });\n}\n\nif (window !== undefined) {\n  Object.assign(window, { IncrementalIndexedDBAdapter });\n}\n"],
  "mappings": "+EAKA,IAAMA,EACJ,OAAO,QAAW,aAAe,CAAC,CAAC,OAAO,6BAsC/BC,EAAN,KAEP,CACE,YAAYC,EAAS,CACnB,KAAK,KAAO,cACZ,KAAK,QAAUA,GAAW,CAAC,EAC3B,KAAK,UAAY,IACjB,KAAK,eAAiB,KAAK,QAAQ,gBAAkB,GAErD,KAAK,IAAM,KACX,KAAK,6BAA+B,KACpC,KAAK,YAAc,KAEnB,KAAK,mBAAqB,KAC1B,KAAK,0BAA4B,CAAC,EAElC,IAAMC,EAAwB,CAAC,CAAC,KAAK,QAAQ,QAC7C,GAAIA,EAAuB,CACzB,GAAIA,GAAyB,CAAC,KAAK,QAAQ,QACzC,MAAM,MACJ,0EACF,EAEF,GAAIA,GAAyB,CAACC,EAAW,KAAK,QAAQ,OAAO,EAC3D,MAAM,MAAM,iDAAiD,EAE/D,GAAID,GAAyB,CAACC,EAAW,KAAK,QAAQ,OAAO,EAC3D,MAAM,MAAM,iDAAiD,EAE/D,KAAK,QAAUC,EACb,KAAK,QAAQ,QACZC,GAAM,yDAAyDA,GAClE,EACA,KAAK,QAAUD,EACb,KAAK,QAAQ,QACZC,GACC,uFAAuFA,GAC3F,EAEA,KAAK,OAAS,CACZ,gBAAiB,MACjB,YAAa,kBACb,MAAO,KACP,SAAU,OACZ,OAEA,KAAK,QAAUC,EACf,KAAK,QAAUA,EACf,KAAK,OAAS,CACZ,gBAAiB,sBACjB,YAAa,OACb,MAAO,QACP,SAAU,UACZ,EAGF,GAAI,EAAE,KAAK,gBAAkB,GAAK,KAAK,eAAiB,IAAM,GAC5D,MAAM,IAAI,MAAM,+CAA+C,CAEnE,CAGA,UAAUC,EAAYC,EAAS,CAE7B,IAAMC,EAAQD,EAAU,KAAK,UACvBE,EAAQD,EAAQ,KAAK,UAAY,EAGvCF,EAAW,SAAS,EACpB,IAAMI,EAAUJ,EAAW,QAEvBK,EAAoB,KAEpBC,EAAMF,EAAQ,OAAS,EACvBG,EAAM,EACNC,EAEJ,KAAOJ,EAAQG,CAAG,EAAIH,EAAQE,CAAG,GAC/BE,EAAOD,EAAMD,GAAQ,EAEjBF,EAAQI,CAAG,EAAIN,EACjBK,EAAMC,EAAM,EAEZF,EAAME,EAQV,GAJIF,IAAQC,GAAOH,EAAQG,CAAG,GAAKL,GAASE,EAAQG,CAAG,GAAKJ,IAC1DE,EAAoBE,GAGlBF,IAAsB,KAExB,MAAO,CAAC,EAOV,IAAII,EAAmB,KACvB,QACMC,EAAIL,EAAoB,KAAK,UAAY,EAC7CK,GAAKL,EACLK,IAEA,GAAIN,EAAQM,CAAC,GAAKP,EAAO,CACvBM,EAAmBC,EACnB,MAKJ,IAAMC,EAAeX,EAAW,KAAKK,CAAiB,EACtD,GACE,EACEM,GACAA,EAAa,OAAST,GACtBS,EAAa,OAASR,GAGxB,MAAM,IAAI,MAAM,+BAA+B,EAGjD,IAAMS,EAAcZ,EAAW,KAAKS,CAAgB,EACpD,GACE,EAAEG,GAAeA,EAAY,OAASV,GAASU,EAAY,OAAST,GAEpE,MAAM,IAAI,MAAM,8BAA8B,EAKhD,IAAMU,EAAYb,EAAW,KAAK,MAChCK,EACAI,EAAmB,CACrB,EAEA,GAAII,EAAU,OAAS,KAAK,UAC1B,MAAM,IAAI,MAAM,+BAA+B,EAGjD,OAAOA,CACT,CAiBA,aAAaC,EAAQC,EAAaC,EAAU,CAC1C,IAAMC,EAAO,KAEb,GAAI,CAAC,KAAK,IAAK,CACb,KAAK,eAAeH,EAAQE,EAAU,IAAM,CAC1CC,EAAK,aAAaH,EAAQC,EAAaC,CAAQ,CACjD,CAAC,EACD,OAGF,GAAI,KAAK,oBACP,MAAM,IAAI,MACR,iIACF,EAEF,KAAK,oBAAsB,GAE3BxB,GAAS,QAAQ,IAAI,sBAAsB,EAC3CA,GAAS,QAAQ,KAAK,cAAc,EACpC,SAAS0B,EAAOC,EAAG,CACjB3B,GAAS2B,GAAK,QAAQ,MAAMA,CAAC,EAC7B3B,GAAS,QAAQ,QAAQ,cAAc,EACvCyB,EAAK,oBAAsB,GAC3BD,EAASG,CAAC,CACZ,CALSC,EAAAF,EAAA,UAUT,GAAI,CACF,IAAIG,EAAuBD,EAAA,IAAM,CAC/B,QAAQ,MACN,+DACF,CACF,EAJ2B,wBAKvBE,EAAe,GAEbC,EAAK,KAAK,IAAI,YAClB,CAACN,EAAK,4BAA4B,EAClC,WACF,EACAM,EAAG,WAAa,IAAM,CACpBF,EAAqB,EACrBH,EAAO,EACHI,GAAgBL,EAAK,QAAQ,gBAC/BA,EAAK,QAAQ,eAAe,CAEhC,EAEAM,EAAG,QAAWJ,GAAM,CAClBD,EAAOC,CAAC,CACV,EAEAI,EAAG,QAAWJ,GAAM,CAClBD,EAAOC,CAAC,CACV,EAEA,IAAMK,EAAQD,EAAG,YAAYN,EAAK,4BAA4B,EAExDQ,EAAcL,EAACM,GAAgB,CACnC,GAAI,CACF,IAAMC,EAAc,CAACD,EACfE,EAAYX,EAAK,aACrBO,EACAT,EAAY,EACZY,EACAD,CACF,EAEAL,EAAuBD,EAAA,IAAM,CAC3BH,EAAK,mBAAqBW,EAAU,cACpCA,EAAU,qBAAqB,QAAQ,CAAC,CAAE,KAAAC,EAAM,UAAAC,CAAU,IAAM,CAC9Db,EAAK,0BAA0BY,CAAI,EAAIC,CACzC,CAAC,CACH,EALuB,wBAMvBP,EAAG,QAAUA,EAAG,OAAO,CACzB,OAASQ,EAAP,CACA,QAAQ,MAAM,2BAA4BA,CAAK,EAC/CR,EAAG,MAAM,CACX,CACF,EArBoB,eAiCdS,EAAqBZ,EAAA,IAAM,CAG/Ba,EACET,EAAM,WAAW,EACjB,CAAC,CAAE,OAAAU,CAAO,IAAM,CACd,IAAMR,EAAcS,EAAeD,EAAO,OAAQjB,EAAK,WAAW,EAClEQ,EAAYC,CAAW,CACzB,EACCP,GAAM,CACL,QAAQ,MAAM,4BAA6BA,CAAC,EAC5CI,EAAG,MAAM,CACX,CACF,CACF,EAd2B,sBAgBHH,EAAA,IAAM,CAC5Ba,EACET,EAAM,IAAIP,EAAK,YAAY,aAAa,EACxC,CAAC,CAAE,OAAAiB,CAAO,IAAM,CAEZE,EAAmBF,EAAO,OAAQjB,EAAK,OAAO,IAC9CA,EAAK,mBAELQ,EAAY,GAEZjC,GACE,QAAQ,KACN,qDACF,EACF8B,EAAe,GACfU,EAAmB,EAEvB,EACCb,GAAM,CACL,QAAQ,MAAM,8BAA+BA,CAAC,EAC9CI,EAAG,MAAM,CACX,CACF,CACF,EAvBwB,mBAyBR,CAClB,OAASQ,EAAP,CACAb,EAAOa,CAAK,CACd,CACF,CAEA,aAAaM,EAAUC,EAAMX,EAAaD,EAAa,CACrD,IAAMT,EAAO,KACPsB,EAAuB,CAAC,EAC1BC,EAAY,EAEVC,EAAoBrB,EAAA,CAACpB,EAAYU,IAAM,CAE3C,IAAMgC,EAAc,IAAI,IACxBf,GACE3B,EAAW,SAAS,QAAS2C,GAAW,CACtC,IAAM1C,EAAW0C,EAAS1B,EAAK,UAAa,EAC5CyB,EAAY,IAAIzC,CAAO,CACzB,CAAC,EACHD,EAAW,SAAW,CAAC,EAGvB,IAAM4C,EAAexB,EAACnB,GAAY,CAChC,IAAIY,EAAYI,EAAK,UAAUjB,EAAYC,CAAO,EAC9CgB,EAAK,QAAQ,iBACfJ,EAAYI,EAAK,QAAQ,eAAejB,EAAW,KAAMa,CAAS,GAKpEA,EAAYI,EAAK,QAAQ,KAAK,UAAUJ,CAAS,CAAC,EAClD2B,GAAa3B,EAAU,OACvBrB,GACEmC,GACA,QAAQ,IAAI,WAAW3B,EAAW,cAAcC,GAAS,EAC3DoC,EAAS,IAAI,CACX,IAAKpB,EAAK,YAAY,0CACpBjB,EAAW,KACXC,CACF,EACA,MAAOY,CACT,CAAC,CACH,EApBqB,gBAqBrB,GAAIc,EACFe,EAAY,QAAQE,CAAY,MAC3B,CAEL,IAAMC,EAAc7C,EAAW,MAAQiB,EAAK,UAAa,EACzD,QAAS6B,EAAI,EAAGA,GAAKD,EAAYC,GAAK,EACpCF,EAAaE,CAAC,EAMhB,IAAMC,EAAsBrB,EAAY1B,EAAW,IAAI,GAAK,EAC5D,QAASgD,EAAIH,EAAa,EAAGG,GAAKD,EAAqBC,GAAK,EAAG,CAC7D,IAAMC,EACJhC,EAAK,YAAY,0CACfjB,EAAW,KACXgD,CACF,EACFX,EAAS,OAAOY,CAAgB,EAChCzD,GAAS,QAAQ,KAAK,kBAAkByD,GAAkB,GAK9D,GAAIjD,EAAW,OAAS0C,EAAY,MAAQ,CAACf,EAAa,CACxD3B,EAAW,QAAU,CAAC,EACtBA,EAAW,KAAO,CAAC,EACnBA,EAAW,aAAekD,EAAgB,EAC1CX,EAAqB,KAAK,CACxB,KAAMvC,EAAW,KACjB,UAAWA,EAAW,YACxB,CAAC,EAED,IAAMmD,EAAgBlC,EAAK,QAAQ,KAAK,UAAUjB,CAAU,CAAC,EAC7DwC,GAAaW,EAAc,OAC3B3D,GACEmC,GACA,QAAQ,IAAI,WAAW3B,EAAW,eAAe,EACnDqC,EAAS,IAAI,CACX,IAAKpB,EAAK,YAAY,6CACpBjB,EAAW,IACb,EACA,MAAOmD,CACT,CAAC,EAIHb,EAAK,YAAY5B,CAAC,EAAI,CAAE,KAAMV,EAAW,IAAK,CAChD,EAjF0B,qBAkF1BsC,EAAK,YAAY,QAAQG,CAAiB,EAE1CH,EAAK,aAAeY,EAAgB,EACpC,IAAME,EAAqBnC,EAAK,QAAQ,KAAK,UAAUqB,CAAI,CAAC,EAC5D,OAAAE,GAAaY,EAAmB,OAEhC5D,GAASmC,GAAe,QAAQ,IAAI,cAAc,EAClDU,EAAS,IAAI,CACX,IAAKpB,EAAK,YAAY,cACtB,MAAOmC,CACT,CAAC,EAED5D,GAAS,QAAQ,IAAI,eAAegD,GAAW,EACxC,CACL,cAAeF,EAAK,aACpB,qBAAAC,CACF,CACF,CAiBA,aAAazB,EAAQE,EAAU,CAC7B,IAAMC,EAAO,KAEb,GAAI,KAAK,oBACP,MAAM,IAAI,MACR,+HACF,EAGF,KAAK,oBAAsB,GAE3BzB,GAAS,QAAQ,IAAI,sBAAsB,EAC3CA,GAAS,QAAQ,KAAK,cAAc,EAEpC,IAAM0B,EAASE,EAACiC,GAAU,CACxB7D,GAAS,QAAQ,QAAQ,cAAc,EACvCyB,EAAK,oBAAsB,GAC3BD,EAASqC,CAAK,CAChB,EAJe,UAMf,KAAK,cAAcvC,EAASwC,GAAW,CACrC,GAAI,CACF,GAAI,CAAC,MAAM,QAAQA,CAAM,EACvB,MAAMA,EAGR,GAAI,CAACA,EAAO,OACV,OAAOpC,EAAO,IAAI,EAGpB1B,GAAS,QAAQ,IAAI,gBAAiB8D,EAAO,MAAM,EAGnDA,EAASC,EAAYD,EAAQrC,EAAK,WAAW,EAC7C,IAAMqB,EAAOgB,EAAO,KACpB,OAAAA,EAAO,KAAO,KAGdE,EAAalB,EAAMgB,EAAO,QAAQ,EAClCA,EAAS,KAGTrC,EAAK,mBAAqBqB,EAAK,cAAgB,KAC/CrB,EAAK,0BAA4B,CAAC,EAClCqB,EAAK,YAAY,QAAQ,CAAC,CAAE,KAAAT,EAAM,aAAA4B,CAAa,IAAM,CACnDxC,EAAK,0BAA0BY,CAAI,EAAI4B,GAAgB,IACzD,CAAC,EAEMvC,EAAOoB,CAAI,CACpB,OAASP,EAAP,CACA,OAAAd,EAAK,mBAAqB,KAC1BA,EAAK,0BAA4B,CAAC,EAC3BC,EAAOa,CAAK,CACrB,CACF,CAAC,CACH,CAEA,eAAejB,EAAQ4C,EAASC,EAAW,CACzC,IAAM1C,EAAO,KAGb,GAFAzB,GAAS,QAAQ,IAAI,kBAAkB,EAEnC,KAAK,kBACP,MAAM,IAAI,MACR,2DACF,EAEF,KAAK,kBAAoB,GAEzB,IAAMoE,EAAc,UAAU,KAAK9C,EAAQ,CAAC,EAE5C8C,EAAY,gBAAkB,CAAC,CAAE,OAAA1B,EAAQ,WAAA2B,CAAW,IAAM,CACxD,IAAMC,EAAK5B,EAAO,OAGlB,GAFA1C,GAAS,QAAQ,IAAI,iCAAiCqE,GAAY,EAE9DA,EAAa,EAEfC,EAAG,kBAAkB7C,EAAK,QAAQA,EAAK,OAAO,eAAe,EAAG,CAC9D,QAAS,KACX,CAAC,MAGD,OAAM,IAAI,MACR,uBAAuB4C,yBACzB,CAEJ,EAEAD,EAAY,UAAY,CAAC,CAAE,OAAA1B,CAAO,IAAM,CACtCjB,EAAK,kBAAoB,GACzB,IAAM6C,EAAK5B,EAAO,OAOlB,GANAjB,EAAK,IAAM6C,EACX7C,EAAK,6BAA+B8C,EAClCD,EACA7C,EAAK,OAAO,gBACZA,EAAK,OACP,EACI,CAACA,EAAK,6BAA8B,CACtCyC,EACE,IAAI,MACF,kCAAkCzC,EAAK,OAAO,kBAC5CA,EAAK,QAAU,qCAAuC,IAE1D,CACF,EAEAA,EAAK,eAAeH,CAAM,EAC1B,OAOF,IAAMU,EAJKP,EAAK,IAAI,YAClB,CAACA,EAAK,4BAA4B,EAClC,UACF,EACiB,YAAYA,EAAK,4BAA4B,EAC9D+C,EAAmBxC,EAAOP,EAAK,OAAQA,EAAK,QAASA,EAAK,OAAO,EAC9D,KAAMgD,GAAgB,CACrBhD,EAAK,YAAcgD,EAEnBzE,GAAS,QAAQ,IAAI,cAAc,EAEnCsE,EAAG,gBAAmBI,GAAuB,CAEvCjD,EAAK,MAAQ6C,IAIjBtE,GAAS,QAAQ,IAAI,qBAAsB0E,CAAkB,EAO7DjD,EAAK,IAAI,MAAM,EACfA,EAAK,IAAM,KACPA,EAAK,QAAQ,iBACfA,EAAK,QAAQ,gBAAgBiD,CAAkB,EAEnD,EAEAP,EAAU,CACZ,CAAC,EACA,MAAOxC,GAAM,CACZ,cAAQ,MAAM,gDAAiDA,CAAC,EAC1DA,CACR,CAAC,CACL,EAEAyC,EAAY,UAAazC,GAAM,CAC7B,QAAQ,MAAM,4BAA6BA,CAAC,EAC5CuC,EAAQ,IAAI,MAAM,8CAA8C,CAAC,CACnE,EAEAE,EAAY,QAAWzC,GAAM,CAC3BF,EAAK,kBAAoB,GACzB,QAAQ,MAAM,uBAAwBE,CAAC,EACvCuC,EAAQvC,CAAC,CACX,CACF,CAEA,cAAcL,EAAQE,EAAU,CAC9B,IAAMC,EAAO,KACb,GAAI,CAAC,KAAK,IAAK,CACb,KAAK,eAAeH,EAAQE,EAAU,IAAM,CAC1CC,EAAK,cAAcH,EAAQE,CAAQ,CACrC,CAAC,EACD,OAOF,IAAMQ,EAJK,KAAK,IAAI,YAClB,CAACP,EAAK,4BAA4B,EAClC,UACF,EACiB,YAAYA,EAAK,4BAA4B,EAK9D,SAASkD,EAAcC,EAAM,CAC3B,IAAMC,EAAiBpD,EAAK,eACtBqD,EAAYC,EAAgBH,EAAMC,CAAc,EAEhDG,EAAY,CAAC,EACfC,EAAqB,EAEzB,SAASC,EAAiB,CAAE,OAAAxC,CAAO,EAAGyC,EAAgBC,EAAU,CAG9D,IAAMC,EAAY3C,EAAO,OACzB2C,EAAU,QAAQ,CAACC,EAAOpE,IAAM,CAC9BqE,EACED,EACA7D,EAAK,iBACLA,EAAK,YACLA,EAAK,OACP,EACAuD,EAAU,KAAKM,CAAK,EACpBD,EAAUnE,CAAC,EAAI,IACjB,CAAC,EAGD+D,GAAsB,EAClBA,IAAuBJ,GACzBrD,EAASwD,CAAS,CAEtB,CApBSpD,EAAAsD,EAAA,oBAwBT,SAASM,EAAiBC,EAAO,CAC/B,IAAML,EAAWN,EAAUW,CAAK,EAChChD,EACET,EAAM,OAAOoD,CAAQ,EACpBzD,GAAM,CACD8D,EAAQZ,EAAiB,GAC3BW,EAAiBC,EAAQZ,EAAiB,CAAC,EAG7CK,EAAiBvD,EAAG8D,EAAOL,CAAQ,CACrC,EACCzD,GAAM,CACLH,EAASG,CAAC,CACZ,CACF,CACF,CAfSC,EAAA4D,EAAA,oBAiBT,QAAStE,EAAI,EAAGA,EAAI2D,EAAiB,EAAG3D,GAAK,EAC3CsE,EAAiBtE,CAAC,CAEtB,CAnDSU,EAAA+C,EAAA,iBAqDT,SAASe,GAAe,CACtBjD,EACET,EAAM,OAAO,EACb,CAAC,CAAE,OAAAU,CAAO,IAAM,CACd,IAAMsC,EAAYtC,EAAO,OACzBsC,EAAU,QAASM,GAAU,CAC3BC,EACED,EACA7D,EAAK,iBACLA,EAAK,YACLA,EAAK,OACP,CACF,CAAC,EACDD,EAASwD,CAAS,CACpB,EACCrD,GAAM,CACLH,EAASG,CAAC,CACZ,CACF,CACF,CAnBSC,EAAA8D,EAAA,gBAqBT,SAASC,GAAa,CACpBlD,EACET,EAAM,WAAW,EACjB,CAAC,CAAE,OAAAU,CAAO,IAAM,CACd,IAAMkC,EAAOlC,EAAO,OAAO,KAAK,EAC5BkC,EAAK,OAAS,IAChBD,EAAcC,CAAI,EAElBc,EAAa,CAEjB,EACC/D,GAAM,CACLH,EAASG,CAAC,CACZ,CACF,EAEIF,EAAK,QAAQ,cACfA,EAAK,QAAQ,aAAa,CAE9B,CAnBSG,EAAA+D,EAAA,cAqBTA,EAAW,CACb,CAgBA,eAAerE,EAAQE,EAAU,CAC/B,GAAI,KAAK,oBACP,MAAM,IAAI,MACR,gIACF,EAGF,KAAK,oBAAsB,GAE3B,IAAMC,EAAO,KACbzB,GAAS,QAAQ,IAAI,wBAAwB,EAC7CA,GAAS,QAAQ,KAAK,gBAAgB,EAEtC,KAAK,mBAAqB,KAC1B,KAAK,0BAA4B,CAAC,EAE9B,KAAK,MACP,KAAK,IAAI,MAAM,EACf,KAAK,IAAM,MAGb,IAAM4F,EAAU,UAAU,eAAetE,CAAM,EAE/CsE,EAAQ,UAAY,IAAM,CACxBnE,EAAK,oBAAsB,GAC3BzB,GAAS,QAAQ,QAAQ,gBAAgB,EACzCwB,EAAS,CAAE,QAAS,EAAK,CAAC,CAC5B,EAEAoE,EAAQ,QAAWjE,GAAM,CACvBF,EAAK,oBAAsB,GAC3B,QAAQ,MAAM,gCAAiCE,CAAC,EAChDH,EAAS,CAAE,QAAS,EAAM,CAAC,CAC7B,EAEAoE,EAAQ,UAAajE,GAAM,CAGzB,QAAQ,MACN,sEACAA,CACF,CACF,CACF,CACF,EAlvBaC,EAAA3B,EAAA,+BAqvBb,SAAS0C,EAAekD,EAAmBpB,EAAa,CACtD,IAAMvC,EAAc,CAAC,EAErB,OAAA2D,EAAkB,QAASC,GAAkB,CAE3C,GAAIrB,EAAY,WAAWqB,CAAa,EAAG,CACzC,IAAMtF,EACJiE,EAAY,uCAAuCqB,CAAa,EAC5DrF,EAAUsF,EAA2BD,CAAa,GAAK,EACvDE,EAAa9D,EAAY1B,CAAU,GAErC,CAACwF,GAAcvF,EAAUuF,KAC3B9D,EAAY1B,CAAU,EAAIC,GAGhC,CAAC,EACMyB,CACT,CAjBSN,EAAAe,EAAA,kBAmBT,SAASC,EAAmB0C,EAAOW,EAAW,CAC5C,GAAI,CACF,OAAIX,GACW,KAAK,MAAMW,EAAUX,EAAM,KAAK,CAAC,EAClC,cAAgB,IAIhC,OAAS3D,EAAP,CACA,eAAQ,MAAM,iCAAkCA,CAAC,EAC1C,IACT,CACF,CAZSC,EAAAgB,EAAA,sBAcT,SAASmB,EAAYD,EAAQW,EAAa,CACxC,IAAI3B,EACEoD,EAAW,CAAC,EAsClB,GApCAC,EAAkBrC,EAAQW,CAAW,EAErCX,EAAO,QAASsC,GAAW,CACzB,IAAMC,EAAMD,EAAO,IACbvC,EAAQuC,EAAO,MACrB,GAAI3B,EAAY,UAAU4B,CAAG,EAAG,CAC9BvD,EAAOe,EACP,WACK,CACL,GAAIY,EAAY,WAAW4B,CAAG,EAAG,CAC/B,IAAMC,EAAU7B,EAAY,uCAAuC4B,CAAG,EAClEH,EAASI,CAAO,EAClBJ,EAASI,CAAO,EAAE,WAAW,KAAKzC,CAAK,EAEvCqC,EAASI,CAAO,EAAI,CAClB,SAAU,KACV,WAAY,CAACzC,CAAK,CACpB,EAEF,OAEF,GAAIY,EAAY,cAAc4B,CAAG,EAAG,CAClC,IAAMhE,EAAOoC,EAAY,gCAAgC4B,CAAG,EACxDH,EAAS7D,CAAI,EACf6D,EAAS7D,CAAI,EAAE,SAAWwB,EAE1BqC,EAAS7D,CAAI,EAAI,CAAE,SAAUwB,EAAO,WAAY,CAAC,CAAE,EAErD,QAIJ,cAAQ,MAAM,iBAAiBwC,GAAK,EAC9B,IAAI,MAAM,0CAA0C,CAC5D,CAAC,EAEG,CAACvD,EACH,MAAM,IAAI,MAAM,gDAAgD,EAGlE,MAAO,CAAE,KAAAA,EAAM,SAAAoD,CAAS,CAC1B,CA7CStE,EAAAmC,EAAA,eA+CT,SAASC,EAAa,CAAE,YAAAuC,CAAY,EAAGL,EAAU,CAC/CK,EAAY,QAAQ3E,EAAA,SAA4B4E,EAAgBtF,EAAG,CACjE,IAAMuF,EAAkBP,EAASM,EAAe,IAAI,EACpD,GAAIC,EAAiB,CACnB,GAAI,CAACA,EAAgB,SACnB,MAAM,IAAI,MACR,mDAAmDD,EAAe,MACpE,EAEF,IAAMhG,EAAaiG,EAAgB,SACnCA,EAAgB,SAAW,KAE3BF,EAAYrF,CAAC,EAAIV,EAEjB,IAAMkG,EAAaD,EAAgB,WACnCC,EAAW,QAAQ9E,EAAA,SAAuB0D,EAAOpE,EAAG,CAClDoE,EAAM,QAASqB,GAAQ,CACrBnG,EAAW,KAAK,KAAKmG,CAAG,CAC1B,CAAC,EACDD,EAAWxF,CAAC,EAAI,IAClB,EALmB,gBAKlB,EAEL,EArBoB,qBAqBnB,CACH,CAvBSU,EAAAoC,EAAA,gBAyBT,SAASuB,EAAWD,EAAOsB,EAAkBnC,EAAawB,EAAW,CAEnE,GADAX,EAAM,MAAQ,KAAK,MAAMW,EAAUX,EAAM,KAAK,CAAC,EAC3CsB,GACEnC,EAAY,WAAWa,EAAM,GAAG,EAAG,CACrC,IAAMuB,EAAiBpC,EAAY,uCACjCa,EAAM,GACR,EACAA,EAAM,MAAQsB,EAAiBC,EAAgBvB,EAAM,KAAK,EAGhE,CAVS1D,EAAA2D,EAAA,cAYT,SAAS7B,GAAkB,CAIzB,OAAO,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC,CAC/C,CALS9B,EAAA8B,EAAA,mBAOT,SAASoD,EAAYV,EAAQ3B,EAAa,CACxC,IAAM4B,EAAMD,EAAO,IACnB,OAAI3B,EAAY,WAAW4B,CAAG,EACrBN,EAA2BM,CAAG,EAGhC,EACT,CAPSzE,EAAAkF,EAAA,eAST,SAASX,EAAkBrC,EAAQW,EAAa,CAG9CX,EAAO,KAAK,CAACxD,EAAGyG,IAAM,CACpB,IAAMC,EAAOF,EAAYxG,EAAGmE,CAAW,EACjCwC,EAAOH,EAAYC,EAAGtC,CAAW,EACvC,OAAIuC,EAAOC,EAAa,GACpBD,EAAOC,EAAa,EACjB,CACT,CAAC,CACH,CAVSrF,EAAAuE,EAAA,qBAYT,SAASpB,EAAgBH,EAAMsC,EAAO,CACpC,IAAMC,EAAgB,KAAK,MAAMvC,EAAK,OAASsC,CAAK,EAC9CpC,EAAY,CAAC,EACfsC,EACAC,EACJ,QAAS,EAAI,EAAG,EAAIH,EAAO,GAAK,EAC9BE,EAASxC,EAAKuC,EAAgB,CAAC,EAC/BE,EAASzC,EAAKuC,GAAiB,EAAI,EAAE,EACjC,IAAM,EAERrC,EAAU,KAAK,YAAY,WAAWuC,EAAQ,EAAI,CAAC,EAC1C,IAAMH,EAAQ,EAEvBpC,EAAU,KAAK,YAAY,WAAWsC,CAAM,CAAC,EAG7CtC,EAAU,KAAK,YAAY,MAAMsC,EAAQC,EAAQ,GAAO,EAAI,CAAC,EAGjE,OAAOvC,CACT,CApBSlD,EAAAmD,EAAA,mBAsBT,SAAStC,EAAOmD,EAAS0B,EAAWC,EAAS,CAC3C,OAAA3B,EAAQ,UAAajE,GAAM,CACzB,GAAI,CACF,OAAO2F,EAAU3F,CAAC,CACpB,OAASY,EAAP,CACAgF,EAAQhF,CAAK,CACf,CACF,EACAqD,EAAQ,QAAU2B,EACX3B,CACT,CAVShE,EAAAa,EAAA,UAYT,SAAS8B,EACP,CAAE,iBAAAiD,CAAiB,EACnBC,EACAxB,EACA,CACA,IAAMyB,EAAgBF,EACtB,QAAStG,EAAI,EAAGA,EAAIwG,EAAc,OAAQxG,IACxC,GAAI+E,EAAUyB,EAAcxG,CAAC,CAAC,IAAMuG,EAClC,OAAOC,EAAcxG,CAAC,EAG1B,OAAO,IACT,CAZSU,EAAA2C,EAAA,oCAcT,SAASnE,EAAWuH,EAAI,CACtB,OAAO,OAAOA,GAAO,UACvB,CAFS/F,EAAAxB,EAAA,cAIT,SAASG,EAAUqH,EAAG,CACpB,OAAOA,CACT,CAFShG,EAAArB,EAAA,aAIT,SAASF,EAAyBsH,EAAIE,EAAsB,CAC1D,OAAO,YAAaC,EAAM,CACxB,GAAI,CACF,OAAOH,EAAG,MAAM,KAAMG,CAAI,CAC5B,OAASnG,EAAP,CACA,cAAQ,MAAMkG,EAAqBC,CAAI,EAAGnG,CAAC,EACrCA,CACR,CACF,CACF,CATSC,EAAAvB,EAAA,4BAWT,SAAS0H,EAA0B1B,EAAK,CACtC,IAAM2B,EAAyB3B,EAAI,MAAM,aAAa,EACtD,OAAI2B,IAA2B,KACtB,KAEFA,EAAuB,CAAC,CACjC,CANSpG,EAAAmG,EAAA,6BAQT,SAAShC,EAA2BM,EAAK,CACvC,IAAM5F,EAAU4F,EAAI,MAAM,aAAa,EACvC,OAAI5F,IAAY,KACP,KAEF,SAASA,EAAQ,CAAC,EAAG,EAAE,CAChC,CANSmB,EAAAmE,EAAA,8BAQT,SAASkC,EAAqBC,EAAoBC,EAAQlC,EAAW,CACnE,IAAMmC,EACJL,EAA0BG,CAAkB,EAC9C,GAAI,CAACE,EACH,MAAO,GAET,IAAMC,EAAkCpC,EACtCmC,CACF,EACA,OAAOE,EACLD,EACAF,CACF,CACF,CAbSvG,EAAAqG,EAAA,wBAeT,SAASK,EACPD,EACA,CAAE,MAAA/C,CAAM,EACR,CACA,OACE+C,EAAgC,OAC9BA,EAAgC,YAAY,IAAI/C,GAAO,EACvD,IAAIA,IAAQ,SACd,CAEJ,CAVS1D,EAAA0G,EAAA,qCAYT,SAASC,EAA2CC,EAAmBL,EAAQ,CAC7E,IAAME,EACJN,EAA0BS,CAAiB,EAC7C,MAAI,CAACH,IAAoC,KAChC,KAEFI,EACLJ,EACAF,CACF,CACF,CAVSvG,EAAA2G,EAAA,8CAYT,SAASE,EACPJ,EACA,CAAE,MAAA/C,CAAM,EACR,CACA,IAAMoD,EAA0BL,EAAgC,YAC9D,IAAI/C,GACN,EACA,GAAIoD,IAA4B,GAC9B,MAAM,IAAI,MACR,yCAAyCL,iCAA+D/C,IAC1G,EAEF,OAAO+C,EAAgC,UAAU,EAAGK,CAAuB,CAC7E,CAbS9G,EAAA6G,EAAA,4DAeT,SAASE,EAAuBC,EAAsB,CAAE,SAAAC,CAAS,EAAG,CAClE,OACED,EAAqB,OACnBA,EAAqB,YAAY,IAAIC,GAAU,EAC/C,IAAIA,IAAW,SACjB,CAEJ,CAPSjH,EAAA+G,EAAA,0BAST,SAASG,EACPF,EACA,CAAE,SAAAC,CAAS,EACX,CACA,OAAOD,EAAqB,UAC1B,EACAA,EAAqB,YAAY,IAAIC,GAAU,CACjD,CACF,CARSjH,EAAAkH,EAAA,iDAUT,SAAStE,EAAmBxC,EAAOmG,EAAQY,EAAW9C,EAAW,CAG/D,OAFgC8C,EA0CzB,IAAI,QAAQ,CAACC,EAASC,IAAW,CACtCxG,EACET,EAAM,WAAW,EACjB,CAAC,CAAE,OAAAU,CAAO,IAAM,CACd,IAAMkC,EAAOlC,EAAO,OAEhBwG,EAAoB,KAClBC,EAA8D,CAEpE,EACM1E,EAAc,CAClB,iCAAkC,CAElC,EACA,mCAAoC,CAEpC,EAEA,gCAAiC,CAEjC,CACF,EACA,GAAIG,EAAK,SAAW,EAElBsE,EAAoBH,EAAUZ,EAAO,WAAW,MAEhD,SAASjH,EAAI,EAAGA,EAAI0D,EAAK,OAAQ1D,IAAK,CACpC,IAAMmF,EAAMzB,EAAK1D,CAAC,EAClB,GAAI+G,EAAqB5B,EAAK8B,EAAQlC,CAAS,EAAG,CAChD,IAAMmC,EACJL,EAA0B1B,CAAG,EAC/B,GAAI,CAAC+B,EACH,MAAM,MACJ,gEAAgE/B,yDAClE,EAEF,IAAM+C,EACJX,EACExC,EAAUmC,CAAgC,EAC1CD,CACF,EACFgB,EACEC,CACF,EAAIhB,EACJ3D,EAAY,gCACV2D,CACF,EAAIgB,MACC,CACL,IAAMC,EAAepD,EAAUI,CAAG,EAClC,GAAIgD,IAAiBlB,EAAO,YAC1Be,EAAoB7C,UACXsC,EAAuBU,EAAclB,CAAM,EAAG,CACvD,IAAMtB,EACJiC,EACEO,EACAlB,CACF,EACF1D,EAAY,iCAAiCoC,CAAc,EACzDR,EACF5B,EAAY,mCAAmC4B,CAAG,EAChDQ,MAGF,OAAM,MACJ,0FAA0FR,kBAAoBgD,GAChH,GAKJH,EACFF,EAAQ,CACN,cAAeE,EACf,mCACEzE,EAAY,mCACd,UAAUqB,EAAe,CACvB,OAAOA,IAAkBoD,CAC3B,EACA,cAAcpD,EAAe,CAC3B,MAAO,CAAC,CAACrB,EAAY,mCACnBqB,CACF,CACF,EACA,WAAWA,EAAe,CACxB,OAAOmC,EAAqBnC,EAAeqC,EAAQlC,CAAS,CAC9D,EACA,gCAAgCH,EAAe,CAC7C,OAAOrB,EAAY,mCACjBqB,CACF,CACF,EACA,6CAA6Ce,EAAgB,CAC3D,GACE,CAACpC,EAAY,iCAAiCoC,CAAc,EAC5D,CACA,IAAMyC,EAAqBP,EACzB,GAAGlC,KAAkBsB,EAAO,UAC9B,EACA1D,EAAY,iCAAiCoC,CAAc,EACzDyC,EACF7E,EAAY,mCACV6E,CACF,EAAIzC,EAEN,OAAOpC,EAAY,iCACjBoC,CACF,CACF,EACA,uCAAuCR,EAAK,CAC1C,IAAMkD,EAAoBxB,EAA0B1B,CAAG,EACvD,OAAO5B,EAAY,gCACjB8E,CACF,CACF,EACA,0CAA0C1C,EAAgBpG,EAAS,CACjE,GACE,CAAC0I,EACCtC,CACF,EACA,CACA,IAAM2C,EAAmCT,EACvC,GAAGlC,KAAkBsB,EAAO,OAC9B,EACAgB,EACEtC,CACF,EAAI2C,EACJ/E,EAAY,gCACV+E,CACF,EAAI3C,EAEN,MAAO,GAAGsC,EAA4DtC,CAAc,KAAKpG,GAC3F,CACF,CAAC,EAEDwI,EAAO,CACL,QAAS,0EAA0Ed,EAAO,6CAC5F,CAAC,CAEL,EACCxG,GAAM,CACLsH,EAAO,CAAE,QAAS,kCAAmC,EAAAtH,CAAE,CAAC,CAC1D,CACF,CACF,CAAC,EAtLQ,IAAI,QAASqH,GAAY,CAC9BA,EAAQ,CACN,cAAeb,EAAO,YACtB,UAAUkB,EAAc,CACtB,OAAOA,IAAiBlB,EAAO,WACjC,EACA,cAAckB,EAAc,CAC1B,OAAOV,EAAuBU,EAAclB,CAAM,CACpD,EACA,WAAWkB,EAAc,CACvB,IAAMhB,EACJN,EAA0BsB,CAAY,EACxC,OAAKhB,EAGEC,EACLD,EACAF,CACF,EALS,EAMX,EACA,gCAAgCkB,EAAc,CAC5C,OAAOP,EACLO,EACAlB,CACF,CACF,EACA,6CAA6CtB,EAAgB,CAC3D,MAAO,GAAGA,KAAkBsB,EAAO,UACrC,EACA,uCAAuC9B,EAAK,CAC1C,OAAOkC,EAA2ClC,EAAK8B,CAAM,CAC/D,EACA,0CAA0CtB,EAAgBpG,EAAS,CACjE,MAAO,GAAGoG,KAAkBsB,EAAO,SAAS1H,GAC9C,CACF,CAAC,CACH,CAAC,CAmJL,CA3LSmB,EAAA4C,EAAA,sBA6LL,SAAW,QACb,OAAO,OAAO,OAAQ,CAAE,4BAAAvE,CAA4B,CAAC",
  "names": ["DEBUG", "IncrementalIndexedDBAdapter", "options", "shouldSetupEncryption", "isFunction", "makeExternalFunctionSafe", "a", "doNothing", "collection", "chunkId", "minId", "maxId", "idIndex", "firstDataPosition", "max", "min", "mid", "lastDataPosition", "i", "firstElement", "lastElement", "chunkData", "dbname", "getLokiCopy", "callback", "that", "finish", "e", "__name", "updatePrevVersionIds", "didOverwrite", "tx", "store", "performSave", "maxChunkIds", "incremental", "chunkInfo", "name", "versionId", "error", "getAllKeysThenSave", "idbReq", "target", "getMaxChunkIds", "lokiChunkVersionId", "idbStore", "loki", "collectionVersionIds", "savedSize", "prepareCollection", "dirtyChunks", "lokiId", "prepareChunk", "maxChunkId", "j", "persistedMaxChunkId", "k", "deletedChunkName", "randomVersionId", "metadataChunk", "serializedMetadata", "value", "chunks", "chunksToMap", "populateLoki", "idbVersionId", "onError", "onSuccess", "openRequest", "oldVersion", "db", "findIdbActualLokiObjectStoreName", "extractkeyResolver", "keyResolver", "versionChangeEvent", "getMegachunks", "keys", "megachunkCount", "keyRanges", "createKeyRanges", "allChunks", "megachunksReceived", "processMegachunk", "megachunkIndex", "keyRange", "megachunk", "chunk", "parseChunk", "requestMegachunk", "index", "getAllChunks", "getAllKeys", "request", "allCiphertextKeys", "ciphertextKey", "extractChunkIdFromChunkKey", "currentMax", "decryptFn", "chunkMap", "sortChunksInPlace", "object", "key", "colName", "collections", "collectionStub", "chunkCollection", "dataChunks", "doc", "deserializeChunk", "collectionName", "_getSortKey", "b", "aKey", "bKey", "count", "countPerRange", "minKey", "maxKey", "onsuccess", "onerror", "objectStoreNames", "decryptedObjectStoreName", "domStringList", "fn", "x", "erroMessageGenerator", "args", "getChunkKeyWithoutChunkId", "matchKeyWithoutChunkId", "isCiphertextChunkKey", "ciphertextChunkKey", "_names", "ciphertextChunkKeyWithoutChunkId", "plaintextChunkKeyWithoutChunkId", "isPlaintextChunkKeyWithoutChunkId", "extractCollectionNameFromPlaintextChunkKey", "plaintextChunkKey", "extractCollectionNameFromPlaintextChunkKeyWithoutChunkId", "lastIndexOfChunkKeyName", "isPlaintextMetadataKey", "plaintextMetadataKey", "metadata", "extractCollectionNameFromPlaintextMetadataKey", "encryptFn", "resolve", "reject", "ciphertextLokiKey", "plaintextCollectionNamesToCiphertextChunkKeysWithoutChunkId", "plaintextCollectionName", "plaintextKey", "metadataCiphertext", "keyWithoutChunkId", "ciphertextCollectionNameAndChunk"]
}
