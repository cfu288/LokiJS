{
  "version": 3,
  "sources": ["../src/incremental-indexeddb-adapter.js"],
  "sourcesContent": ["(function(root, factory) {\n  if (typeof define === \"function\" && define.amd) {\n    // AMD\n    define([], factory);\n  } else if (typeof exports === \"object\") {\n    // CommonJS\n    module.exports = factory();\n  } else {\n    // Browser globals\n    root.IncrementalIndexedDBAdapter = factory();\n  }\n})(this, function() {\n  return (function() {\n    \"use strict\";\n\n    /* jshint -W030 */\n    var DEBUG = typeof window !== 'undefined' && !!window.__loki_incremental_idb_debug;\n\n    /**\n     * An improved Loki persistence adapter for IndexedDB (not compatible with LokiIndexedAdapter)\n     *     Unlike LokiIndexedAdapter, the database is saved not as one big JSON blob, but split into\n     *     small chunks with individual collection documents. When saving, only the chunks with changed\n     *     documents (and database metadata) is saved to IndexedDB. This speeds up small incremental\n     *     saves by an order of magnitude on large (tens of thousands of records) databases. It also\n     *     avoids Safari 13 bug that would cause the database to balloon in size to gigabytes\n     *\n     *     The `appname` argument is not provided - to distinguish between multiple app on the same\n     *     domain, simply use a different Loki database name\n     *\n     * @example\n     * var adapter = new IncrementalIndexedDBAdapter();\n     *\n     * @constructor IncrementalIndexedDBAdapter\n     *\n     * @param {object=} options Configuration options for the adapter\n     * @param {function} options.onversionchange Function to call on `IDBDatabase.onversionchange` event\n     *     (most likely database deleted from another browser tab)\n     * @param {function} options.onFetchStart Function to call once IDB load has begun.\n     *     Use this as an opportunity to execute code concurrently while IDB does work on a separate thread\n     * @param {function} options.onDidOverwrite Called when this adapter is forced to overwrite contents\n     *     of IndexedDB. This happens if there's another open tab of the same app that's making changes.\n     *     You might use it as an opportunity to alert user to the potential loss of data\n     * @param {function} options.serializeChunk Called with a chunk (array of Loki documents) before\n     *     it's saved to IndexedDB. You can use it to manually compress on-disk representation\n     *     for faster database loads. Hint: Hand-written conversion of objects to arrays is very\n     *     profitable for performance. If you use this, you must also pass options.deserializeChunk.\n     * @param {function} options.deserializeChunk Called with a chunk serialized with options.serializeChunk\n     *     Expects an array of Loki documents as the return value\n     * @param {number} options.megachunkCount Number of parallel requests for data when loading database.\n     *     Can be tuned for a specific application\n     * @param {array} options.lazyCollections Names of collections that should be deserialized lazily\n     *     Only use this for collections that aren't used at launch\n     */\n    function IncrementalIndexedDBAdapter(options) {\n      this.mode = \"incremental\";\n      this.options = options || {};\n      this.chunkSize = 100;\n      this.megachunkCount = this.options.megachunkCount || 24;\n      this.lazyCollections = this.options.lazyCollections || [];\n      this.idb = null; // will be lazily loaded on first operation that needs it\n      this._prevLokiVersionId = null;\n      this._prevCollectionVersionIds = {};\n\n      if (!(this.megachunkCount >= 4 && this.megachunkCount % 2 === 0)) {\n        throw new Error('megachunkCount must be >=4 and divisible by 2');\n      }\n    }\n\n    // chunkId - index of the data chunk - e.g. chunk 0 will be lokiIds 0-99\n    IncrementalIndexedDBAdapter.prototype._getChunk = function(collection, chunkId) {\n      // 0-99, 100-199, etc.\n      var minId = chunkId * this.chunkSize;\n      var maxId = minId + this.chunkSize - 1;\n\n      // use idIndex to find first collection.data position within the $loki range\n      collection.ensureId();\n      var idIndex = collection.idIndex;\n\n      var firstDataPosition = null;\n\n      var max = idIndex.length - 1,\n        min = 0,\n        mid;\n\n      while (idIndex[min] < idIndex[max]) {\n        mid = (min + max) >> 1;\n\n        if (idIndex[mid] < minId) {\n          min = mid + 1;\n        } else {\n          max = mid;\n        }\n      }\n\n      if (max === min && idIndex[min] >= minId && idIndex[min] <= maxId) {\n        firstDataPosition = min;\n      }\n\n      if (firstDataPosition === null) {\n        // no elements in this chunk\n        return [];\n      }\n\n      // find last position\n      // if loki IDs are contiguous (no removed elements), last position will be first + chunk - 1\n      // (and we look back in case there are missing pieces)\n      // TODO: Binary search (not as important as first position, worst case scanario is only chunkSize steps)\n      var lastDataPosition = null;\n      for (var i = firstDataPosition + this.chunkSize - 1; i >= firstDataPosition; i--) {\n        if (idIndex[i] <= maxId) {\n          lastDataPosition = i;\n          break;\n        }\n      }\n\n      // verify\n      var firstElement = collection.data[firstDataPosition];\n      if (!(firstElement && firstElement.$loki >= minId && firstElement.$loki <= maxId)) {\n        throw new Error(\"broken invariant firstelement\");\n      }\n\n      var lastElement = collection.data[lastDataPosition];\n      if (!(lastElement && lastElement.$loki >= minId && lastElement.$loki <= maxId)) {\n        throw new Error(\"broken invariant lastElement\");\n      }\n\n      // this will have *up to* 'this.chunkSize' elements (might have less, because $loki ids\n      // will have holes when data is deleted)\n      var chunkData = collection.data.slice(firstDataPosition, lastDataPosition + 1);\n\n      if (chunkData.length > this.chunkSize) {\n        throw new Error(\"broken invariant - chunk size\");\n      }\n\n      return chunkData;\n    };\n\n    /**\n     * Incrementally saves the database to IndexedDB\n     *\n     * @example\n     * var idbAdapter = new IncrementalIndexedDBAdapter();\n     * var db = new loki('test', { adapter: idbAdapter });\n     * var coll = db.addCollection('testColl');\n     * coll.insert({test: 'val'});\n     * db.saveDatabase();\n     *\n     * @param {string} dbname - the name to give the serialized database\n     * @param {function} getLokiCopy - returns copy of the Loki database\n     * @param {function} callback - (Optional) callback passed obj.success with true or false\n     * @memberof IncrementalIndexedDBAdapter\n     */\n    IncrementalIndexedDBAdapter.prototype.saveDatabase = function(dbname, getLokiCopy, callback) {\n      var that = this;\n\n      if (!this.idb) {\n        this._initializeIDB(dbname, callback, function() {\n          that.saveDatabase(dbname, getLokiCopy, callback);\n        });\n        return;\n      }\n\n      if (this.operationInProgress) {\n        throw new Error(\"Error while saving to database - another operation is already in progress. Please use throttledSaves=true option on Loki object\");\n      }\n      this.operationInProgress = true;\n\n      DEBUG && console.log(\"saveDatabase - begin\");\n      DEBUG && console.time(\"saveDatabase\");\n      function finish(e) {\n        DEBUG && e && console.error(e);\n        DEBUG && console.timeEnd(\"saveDatabase\");\n        that.operationInProgress = false;\n        callback(e);\n      }\n\n      // try..catch is required, e.g.:\n      // InvalidStateError: Failed to execute 'transaction' on 'IDBDatabase': The database connection is closing.\n      // (this may happen if another tab has called deleteDatabase)\n      try {\n        var updatePrevVersionIds = function () {\n          console.error('Unexpected successful tx - cannot update previous version ids');\n        };\n        var didOverwrite = false;\n\n        var tx = this.idb.transaction(['LokiIncrementalData'], \"readwrite\");\n        tx.oncomplete = function() {\n          updatePrevVersionIds();\n          finish();\n          if (didOverwrite && that.options.onDidOverwrite) {\n            that.options.onDidOverwrite();\n          }\n        };\n\n        tx.onerror = function(e) {\n          finish(e);\n        };\n\n        tx.onabort = function(e) {\n          finish(e);\n        };\n\n        var store = tx.objectStore('LokiIncrementalData');\n\n        var performSave = function (maxChunkIds) {\n          try {\n            var incremental = !maxChunkIds;\n            var chunkInfo = that._putInChunks(store, getLokiCopy(), incremental, maxChunkIds);\n            // Update last seen version IDs, but only after the transaction is successful\n            updatePrevVersionIds = function() {\n              that._prevLokiVersionId = chunkInfo.lokiVersionId;\n              chunkInfo.collectionVersionIds.forEach(function (collectionInfo) {\n                that._prevCollectionVersionIds[collectionInfo.name] = collectionInfo.versionId;\n              });\n            };\n            tx.commit && tx.commit();\n          } catch (error) {\n            console.error('idb performSave failed: ', error);\n            tx.abort();\n          }\n        };\n\n        // Incrementally saving changed chunks breaks down if there is more than one writer to IDB\n        // (multiple tabs of the same web app), leading to data corruption. To fix that, we save all\n        // metadata chunks (loki + collections) with a unique ID on each save and remember it. Before\n        // the subsequent save, we read loki from IDB to check if its version ID changed. If not, we're\n        // guaranteed that persisted DB is consistent with our diff. Otherwise, we fall back to the slow\n        // path and overwrite *all* database chunks with our version. Both reading and writing must\n        // happen in the same IDB transaction for this to work.\n        // TODO: We can optimize the slow path by fetching collection metadata chunks and comparing their\n        // version IDs with those last seen by us. Since any change in collection data requires a metadata\n        // chunk save, we're guaranteed that if the IDs match, we don't need to overwrite chukns of this collection\n        var getAllKeysThenSave = function() {\n          // NOTE: We must fetch all keys to protect against a case where another tab has wrote more\n          // chunks whan we did -- if so, we must delete them.\n          idbReq(store.getAllKeys(), function(e) {\n            var maxChunkIds = getMaxChunkIds(e.target.result);\n            performSave(maxChunkIds);\n          }, function(e) {\n            console.error('Getting all keys failed: ', e);\n            tx.abort();\n          });\n        };\n\n        var getLokiThenSave = function() {\n          idbReq(store.get('loki'), function(e) {\n            if (lokiChunkVersionId(e.target.result) === that._prevLokiVersionId) {\n              performSave();\n            } else {\n              DEBUG && console.warn('Another writer changed Loki IDB, using slow path...');\n              didOverwrite = true;\n              getAllKeysThenSave();\n            }\n          }, function(e) {\n            console.error('Getting loki chunk failed: ', e);\n            tx.abort();\n          });\n        };\n\n        getLokiThenSave();\n      } catch (error) {\n        finish(error);\n      }\n    };\n\n    // gets current largest chunk ID for each collection\n    function getMaxChunkIds(allKeys) {\n      var maxChunkIds = {};\n\n      allKeys.forEach(function (key) {\n        var keySegments = key.split(\".\");\n        // table.chunk.2317\n        if (keySegments.length === 3 && keySegments[1] === \"chunk\") {\n          var collection = keySegments[0];\n          var chunkId = parseInt(keySegments[2]) || 0;\n          var currentMax = maxChunkIds[collection];\n\n          if (!currentMax || chunkId > currentMax) {\n            maxChunkIds[collection] = chunkId;\n          }\n        }\n      });\n      return maxChunkIds;\n    }\n\n    function lokiChunkVersionId(chunk) {\n      try {\n        if (chunk) {\n          var loki = JSON.parse(chunk.value);\n          return loki.idbVersionId || null;\n        } else {\n          return null;\n        }\n      } catch (e) {\n        console.error('Error while parsing loki chunk', e);\n        return null;\n      }\n    }\n\n    IncrementalIndexedDBAdapter.prototype._putInChunks = function(idbStore, loki, incremental, maxChunkIds) {\n      var that = this;\n      var collectionVersionIds = [];\n      var savedSize = 0;\n\n      var prepareCollection = function (collection, i) {\n        // Find dirty chunk ids\n        var dirtyChunks = new Set();\n        incremental && collection.dirtyIds.forEach(function(lokiId) {\n          var chunkId = (lokiId / that.chunkSize) | 0;\n          dirtyChunks.add(chunkId);\n        });\n        collection.dirtyIds = [];\n\n        // Serialize chunks to save\n        var prepareChunk = function (chunkId) {\n          var chunkData = that._getChunk(collection, chunkId);\n          if (that.options.serializeChunk) {\n            chunkData = that.options.serializeChunk(collection.name, chunkData);\n          }\n          // we must stringify now, because IDB is asynchronous, and underlying objects are mutable\n          // In general, it's also faster to stringify, because we need serialization anyway, and\n          // JSON.stringify is much better optimized than IDB's structured clone\n          chunkData = JSON.stringify(chunkData);\n          savedSize += chunkData.length;\n          DEBUG && incremental && console.log('Saving: ' + collection.name + \".chunk.\" + chunkId);\n          idbStore.put({\n            key: collection.name + \".chunk.\" + chunkId,\n            value: chunkData,\n          });\n        };\n        if (incremental) {\n          dirtyChunks.forEach(prepareChunk);\n        } else {\n          // add all chunks\n          var maxChunkId = (collection.maxId / that.chunkSize) | 0;\n          for (var j = 0; j <= maxChunkId; j += 1) {\n            prepareChunk(j);\n          }\n\n          // delete chunks with larger ids than what we have\n          // NOTE: we don't have to delete metadata chunks as they will be absent from loki anyway\n          // NOTE: failures are silently ignored, so we don't have to worry about holes\n          var persistedMaxChunkId = maxChunkIds[collection.name] || 0;\n          for (var k = maxChunkId + 1; k <= persistedMaxChunkId; k += 1) {\n            var deletedChunkName = collection.name + \".chunk.\" + k;\n            idbStore.delete(deletedChunkName);\n            DEBUG && console.warn('Deleted chunk: ' + deletedChunkName);\n          }\n        }\n\n        // save collection metadata as separate chunk (but only if changed)\n        if (collection.dirty || dirtyChunks.size || !incremental) {\n          collection.idIndex = []; // this is recreated lazily\n          collection.data = [];\n          collection.idbVersionId = randomVersionId();\n          collectionVersionIds.push({ name: collection.name, versionId: collection.idbVersionId });\n\n          var metadataChunk = JSON.stringify(collection);\n          savedSize += metadataChunk.length;\n          DEBUG && incremental && console.log('Saving: ' + collection.name + \".metadata\");\n          idbStore.put({\n            key: collection.name + \".metadata\",\n            value: metadataChunk,\n          });\n        }\n\n        // leave only names in the loki chunk\n        loki.collections[i] = { name: collection.name };\n      };\n      loki.collections.forEach(prepareCollection);\n\n      loki.idbVersionId = randomVersionId();\n      var serializedMetadata = JSON.stringify(loki);\n      savedSize += serializedMetadata.length;\n\n      DEBUG && incremental && console.log('Saving: loki');\n      idbStore.put({ key: \"loki\", value: serializedMetadata });\n\n      DEBUG && console.log(\"saved size: \" + savedSize);\n      return {\n        lokiVersionId: loki.idbVersionId,\n        collectionVersionIds: collectionVersionIds,\n      };\n    };\n\n    /**\n     * Retrieves a serialized db string from the catalog.\n     *\n     * @example\n     * // LOAD\n     * var idbAdapter = new IncrementalIndexedDBAdapter();\n     * var db = new loki('test', { adapter: idbAdapter });\n     * db.loadDatabase(function(result) {\n     *   console.log('done');\n     * });\n     *\n     * @param {string} dbname - the name of the database to retrieve.\n     * @param {function} callback - callback should accept string param containing serialized db string.\n     * @memberof IncrementalIndexedDBAdapter\n     */\n    IncrementalIndexedDBAdapter.prototype.loadDatabase = function(dbname, callback) {\n      var that = this;\n\n      if (this.operationInProgress) {\n        throw new Error(\"Error while loading database - another operation is already in progress. Please use throttledSaves=true option on Loki object\");\n      }\n\n      this.operationInProgress = true;\n\n      DEBUG && console.log(\"loadDatabase - begin\");\n      DEBUG && console.time(\"loadDatabase\");\n\n      var finish = function (value) {\n        DEBUG && console.timeEnd(\"loadDatabase\");\n        that.operationInProgress = false;\n        callback(value);\n      };\n\n      this._getAllChunks(dbname, function(chunks) {\n        try {\n          if (!Array.isArray(chunks)) {\n            throw chunks; // we have an error\n          }\n\n          if (!chunks.length) {\n            return finish(null);\n          }\n\n          DEBUG && console.log(\"Found chunks:\", chunks.length);\n\n          // repack chunks into a map\n          chunks = chunksToMap(chunks);\n          var loki = chunks.loki;\n          chunks.loki = null; // gc\n\n          // populate collections with data\n          populateLoki(loki, chunks.chunkMap, that.options.deserializeChunk, that.lazyCollections);\n          chunks = null; // gc\n\n          // remember previous version IDs\n          that._prevLokiVersionId = loki.idbVersionId || null;\n          that._prevCollectionVersionIds = {};\n          loki.collections.forEach(function (collection) {\n            that._prevCollectionVersionIds[collection.name] = collection.idbVersionId || null;\n          });\n\n          return finish(loki);\n        } catch (error) {\n          that._prevLokiVersionId = null;\n          that._prevCollectionVersionIds = {};\n          return finish(error);\n        }\n      });\n    };\n\n    function chunksToMap(chunks) {\n      var loki;\n      var chunkMap = {};\n\n      sortChunksInPlace(chunks);\n\n      chunks.forEach(function(chunk) {\n        var type = chunk.type;\n        var value = chunk.value;\n        var name = chunk.collectionName;\n        if (type === \"loki\") {\n          loki = value;\n        } else if (type === \"data\") {\n          if (chunkMap[name]) {\n            chunkMap[name].dataChunks.push(value);\n          } else {\n            chunkMap[name] = {\n              metadata: null,\n              dataChunks: [value],\n            };\n          }\n        } else if (type === \"metadata\") {\n          if (chunkMap[name]) {\n            chunkMap[name].metadata = value;\n          } else {\n            chunkMap[name] = { metadata: value, dataChunks: [] };\n          }\n        } else {\n          throw new Error(\"unreachable\");\n        }\n      });\n\n      if (!loki) {\n        throw new Error(\"Corrupted database - missing database metadata\");\n      }\n\n      return { loki: loki, chunkMap: chunkMap };\n    }\n\n    function populateLoki(loki, chunkMap, deserializeChunk, lazyCollections) {\n      loki.collections.forEach(function populateCollection(collectionStub, i) {\n        var name = collectionStub.name;\n        var chunkCollection = chunkMap[name];\n        if (chunkCollection) {\n          if (!chunkCollection.metadata) {\n            throw new Error(\"Corrupted database - missing metadata chunk for \" + name);\n          }\n          var collection = chunkCollection.metadata;\n          chunkCollection.metadata = null;\n          loki.collections[i] = collection;\n\n          var isLazy = lazyCollections.includes(name);\n          var lokiDeserializeCollectionChunks = function () {\n            DEBUG && isLazy && console.log(\"lazy loading \" + name);\n            var data = [];\n            var dataChunks = chunkCollection.dataChunks;\n            dataChunks.forEach(function populateChunk(chunk, i) {\n              if (isLazy) {\n                chunk = JSON.parse(chunk);\n                if (deserializeChunk) {\n                  chunk = deserializeChunk(name, chunk);\n                }\n              }\n              chunk.forEach(function(doc) {\n                data.push(doc);\n              });\n              dataChunks[i] = null;\n            });\n            return data;\n          };\n          collection.getData = lokiDeserializeCollectionChunks;\n        }\n      });\n    }\n\n    IncrementalIndexedDBAdapter.prototype._initializeIDB = function(dbname, onError, onSuccess) {\n      var that = this;\n      DEBUG && console.log(\"initializing idb\");\n\n      if (this.idbInitInProgress) {\n        throw new Error(\"Cannot open IndexedDB because open is already in progress\");\n      }\n      this.idbInitInProgress = true;\n\n      var openRequest = indexedDB.open(dbname, 1);\n\n      openRequest.onupgradeneeded = function(e) {\n        var db = e.target.result;\n        DEBUG && console.log('onupgradeneeded, old version: ' + e.oldVersion);\n\n        if (e.oldVersion < 1) {\n          // Version 1 - Initial - Create database\n          db.createObjectStore('LokiIncrementalData', { keyPath: \"key\" });\n        } else {\n          // Unknown version\n          throw new Error(\"Invalid old version \" + e.oldVersion + \" for IndexedDB upgrade\");\n        }\n      };\n\n      openRequest.onsuccess = function(e) {\n        that.idbInitInProgress = false;\n        var db = e.target.result;\n        that.idb = db;\n\n        if (!db.objectStoreNames.contains('LokiIncrementalData')) {\n          onError(new Error(\"Missing LokiIncrementalData\"));\n          // Attempt to recover (after reload) by deleting database, since it's damaged anyway\n          that.deleteDatabase(dbname);\n          return;\n        }\n\n        DEBUG && console.log(\"init success\");\n\n        db.onversionchange = function(versionChangeEvent) {\n          // Ignore if database was deleted and recreated in the meantime\n          if (that.idb !== db) {\n            return;\n          }\n\n          DEBUG && console.log('IDB version change', versionChangeEvent);\n          // This function will be called if another connection changed DB version\n          // (Most likely database was deleted from another browser tab, unless there's a new version\n          // of this adapter, or someone makes a connection to IDB outside of this adapter)\n          // We must close the database to avoid blocking concurrent deletes.\n          // The database will be unusable after this. Be sure to supply `onversionchange` option\n          // to force logout\n          that.idb.close();\n          that.idb = null;\n          if (that.options.onversionchange) {\n            that.options.onversionchange(versionChangeEvent);\n          }\n        };\n\n        onSuccess();\n      };\n\n      openRequest.onblocked = function(e) {\n        console.error(\"IndexedDB open is blocked\", e);\n        onError(new Error(\"IndexedDB open is blocked by open connection\"));\n      };\n\n      openRequest.onerror = function(e) {\n        that.idbInitInProgress = false;\n        console.error(\"IndexedDB open error\", e);\n        onError(e);\n      };\n    };\n\n    IncrementalIndexedDBAdapter.prototype._getAllChunks = function(dbname, callback) {\n      var that = this;\n      if (!this.idb) {\n        this._initializeIDB(dbname, callback, function() {\n          that._getAllChunks(dbname, callback);\n        });\n        return;\n      }\n\n      var tx = this.idb.transaction(['LokiIncrementalData'], \"readonly\");\n      var store = tx.objectStore('LokiIncrementalData');\n\n      var deserializeChunk = this.options.deserializeChunk;\n      var lazyCollections = this.lazyCollections;\n\n      // If there are a lot of chunks (>100), don't request them all in one go, but in multiple\n      // \"megachunks\" (chunks of chunks). This improves concurrency, as main thread is already busy\n      // while IDB process is still fetching data. Details: https://github.com/techfort/LokiJS/pull/874\n      function getMegachunks(keys) {\n        var megachunkCount = that.megachunkCount;\n        var keyRanges = createKeyRanges(keys, megachunkCount);\n\n        var allChunks = [];\n        var megachunksReceived = 0;\n\n        function processMegachunk(e, megachunkIndex, keyRange) {\n          // var debugMsg = 'processing chunk ' + megachunkIndex + ' (' + keyRange.lower + ' -- ' + keyRange.upper + ')'\n          // DEBUG && console.time(debugMsg);\n          var megachunk = e.target.result;\n          megachunk.forEach(function (chunk, i) {\n            parseChunk(chunk, deserializeChunk, lazyCollections);\n            allChunks.push(chunk);\n            megachunk[i] = null; // gc\n          });\n          // DEBUG && console.timeEnd(debugMsg);\n\n          megachunksReceived += 1;\n          if (megachunksReceived === megachunkCount) {\n            callback(allChunks);\n          }\n        }\n\n        // Stagger megachunk requests - first one half, then request the second when first one comes\n        // back. This further improves concurrency.\n        var megachunkWaves = 2;\n        var megachunksPerWave = megachunkCount / megachunkWaves;\n        function requestMegachunk(index, wave) {\n          var keyRange = keyRanges[index];\n          idbReq(store.getAll(keyRange), function(e) {\n            if (wave < megachunkWaves) {\n              requestMegachunk(index + megachunksPerWave, wave + 1);\n            }\n\n            processMegachunk(e, index, keyRange);\n          }, function(e) {\n            callback(e);\n          });\n        }\n\n        for (var i = 0; i < megachunksPerWave; i += 1) {\n          requestMegachunk(i, 1);\n        }\n      }\n\n      function getAllChunks() {\n        idbReq(store.getAll(), function(e) {\n          var allChunks = e.target.result;\n          allChunks.forEach(function (chunk) {\n            parseChunk(chunk, deserializeChunk, lazyCollections);\n          });\n          callback(allChunks);\n        }, function(e) {\n          callback(e);\n        });\n      }\n\n      function getAllKeys() {\n        function onDidGetKeys(keys) {\n          keys.sort();\n          if (keys.length > 100) {\n            getMegachunks(keys);\n          } else {\n            getAllChunks();\n          }\n        }\n\n        idbReq(store.getAllKeys(), function(e) {\n          onDidGetKeys(e.target.result);\n        }, function(e) {\n          callback(e);\n        });\n\n        if (that.options.onFetchStart) {\n          that.options.onFetchStart();\n        }\n      }\n\n      getAllKeys();\n    };\n\n    function classifyChunk(chunk) {\n      var key = chunk.key;\n\n      if (key === 'loki') {\n        chunk.type = 'loki';\n        return;\n      } else if (key.includes('.')) {\n        var keySegments = key.split(\".\");\n        if (keySegments.length === 3 && keySegments[1] === \"chunk\") {\n          chunk.type = 'data';\n          chunk.collectionName = keySegments[0];\n          chunk.index = parseInt(keySegments[2], 10);\n          return;\n        } else if (keySegments.length === 2 && keySegments[1] === \"metadata\") {\n          chunk.type = 'metadata';\n          chunk.collectionName = keySegments[0];\n          return;\n        }\n      }\n\n      console.error(\"Unknown chunk \" + key);\n      throw new Error(\"Corrupted database - unknown chunk found\");\n    }\n\n    function parseChunk(chunk, deserializeChunk, lazyCollections) {\n      classifyChunk(chunk);\n\n      var isData = chunk.type === 'data';\n      var isLazy = lazyCollections.includes(chunk.collectionName);\n\n      if (!(isData && isLazy)) {\n        chunk.value = JSON.parse(chunk.value);\n      }\n      if (deserializeChunk && isData && !isLazy) {\n        chunk.value = deserializeChunk(chunk.collectionName, chunk.value);\n      }\n    }\n\n    /**\n     * Deletes a database from IndexedDB\n     *\n     * @example\n     * // DELETE DATABASE\n     * // delete 'finance'/'test' value from catalog\n     * idbAdapter.deleteDatabase('test', function {\n     *   // database deleted\n     * });\n     *\n     * @param {string} dbname - the name of the database to delete from IDB\n     * @param {function=} callback - (Optional) executed on database delete\n     * @memberof IncrementalIndexedDBAdapter\n     */\n    IncrementalIndexedDBAdapter.prototype.deleteDatabase = function(dbname, callback) {\n      if (this.operationInProgress) {\n        throw new Error(\"Error while deleting database - another operation is already in progress. Please use throttledSaves=true option on Loki object\");\n      }\n\n      this.operationInProgress = true;\n\n      var that = this;\n      DEBUG && console.log(\"deleteDatabase - begin\");\n      DEBUG && console.time(\"deleteDatabase\");\n\n      this._prevLokiVersionId = null;\n      this._prevCollectionVersionIds = {};\n\n      if (this.idb) {\n        this.idb.close();\n        this.idb = null;\n      }\n\n      var request = indexedDB.deleteDatabase(dbname);\n\n      request.onsuccess = function() {\n        that.operationInProgress = false;\n        DEBUG && console.timeEnd(\"deleteDatabase\");\n        callback({ success: true });\n      };\n\n      request.onerror = function(e) {\n        that.operationInProgress = false;\n        console.error(\"Error while deleting database\", e);\n        callback({ success: false });\n      };\n\n      request.onblocked = function(e) {\n        // We can't call callback with failure status, because this will be called even if we\n        // succeed in just a moment\n        console.error(\"Deleting database failed because it's blocked by another connection\", e);\n      };\n    };\n\n    function randomVersionId() {\n      // Appears to have enough entropy for chunk version IDs\n      // (Only has to be different than enough of its own previous versions that there's no writer\n      // that thinks a new version is the same as an earlier one, not globally unique)\n      return Math.random().toString(36).substring(2);\n    }\n\n    function sortChunksInPlace(chunks) {\n      // sort chunks in place to load data in the right order (ascending loki ids)\n      // on both Safari and Chrome, we'll get chunks in order like this: 0, 1, 10, 100...\n      chunks.sort(function(a, b) {\n        return (a.index || 0) - (b.index || 0);\n      });\n    }\n\n    function createKeyRanges(keys, count) {\n      var countPerRange = Math.floor(keys.length / count);\n      var keyRanges = [];\n      var minKey, maxKey;\n      for (var i = 0; i < count; i += 1) {\n        minKey = keys[countPerRange * i];\n        maxKey = keys[countPerRange * (i + 1)];\n        if (i === 0) {\n          // ... < maxKey\n          keyRanges.push(IDBKeyRange.upperBound(maxKey, true));\n        } else if (i === count - 1) {\n          // >= minKey\n          keyRanges.push(IDBKeyRange.lowerBound(minKey));\n        } else {\n          // >= minKey && < maxKey\n          keyRanges.push(IDBKeyRange.bound(minKey, maxKey, false, true));\n        }\n      }\n      return keyRanges;\n    }\n\n    function idbReq(request, onsuccess, onerror) {\n      request.onsuccess = function (e) {\n        try {\n          return onsuccess(e);\n        } catch (error) {\n          onerror(error);\n        }\n      };\n      request.onerror = onerror;\n      return request;\n    }\n\n    return IncrementalIndexedDBAdapter;\n  })();\n});\n"],
  "mappings": "+LAAA,8GAAC,SAAS,KAAM,QAAS,CACvB,GAAI,OAAO,SAAW,YAAc,OAAO,IAAK,CAE9C,OAAO,CAAC,EAAG,OAAO,CACpB,SAAW,OAAO,UAAY,SAAU,CAEtC,OAAO,QAAU,QAAQ,CAC3B,KAAO,CAEL,KAAK,4BAA8B,QAAQ,CAC7C,CACF,GAAG,QAAM,UAAW,CAClB,OAAQ,UAAW,CACjB,aAGA,IAAI,MAAQ,OAAO,SAAW,aAAe,CAAC,CAAC,OAAO,6BAqCtD,SAAS,4BAA4B,QAAS,CAC5C,KAAK,KAAO,cACZ,KAAK,QAAU,SAAW,CAAC,EAC3B,KAAK,UAAY,IACjB,KAAK,eAAiB,KAAK,QAAQ,gBAAkB,GACrD,KAAK,gBAAkB,KAAK,QAAQ,iBAAmB,CAAC,EACxD,KAAK,IAAM,KACX,KAAK,mBAAqB,KAC1B,KAAK,0BAA4B,CAAC,EAElC,GAAI,EAAE,KAAK,gBAAkB,GAAK,KAAK,eAAiB,IAAM,GAAI,CAChE,MAAM,IAAI,MAAM,+CAA+C,CACjE,CACF,CAGA,4BAA4B,UAAU,UAAY,SAAS,WAAY,QAAS,CAE9E,IAAI,MAAQ,QAAU,KAAK,UAC3B,IAAI,MAAQ,MAAQ,KAAK,UAAY,EAGrC,WAAW,SAAS,EACpB,IAAI,QAAU,WAAW,QAEzB,IAAI,kBAAoB,KAExB,IAAI,IAAM,QAAQ,OAAS,EACzB,IAAM,EACN,IAEF,MAAO,QAAQ,GAAG,EAAI,QAAQ,GAAG,EAAG,CAClC,IAAO,IAAM,KAAQ,EAErB,GAAI,QAAQ,GAAG,EAAI,MAAO,CACxB,IAAM,IAAM,CACd,KAAO,CACL,IAAM,GACR,CACF,CAEA,GAAI,MAAQ,KAAO,QAAQ,GAAG,GAAK,OAAS,QAAQ,GAAG,GAAK,MAAO,CACjE,kBAAoB,GACtB,CAEA,GAAI,oBAAsB,KAAM,CAE9B,MAAO,CAAC,CACV,CAMA,IAAI,iBAAmB,KACvB,QAAS,EAAI,kBAAoB,KAAK,UAAY,EAAG,GAAK,kBAAmB,IAAK,CAChF,GAAI,QAAQ,CAAC,GAAK,MAAO,CACvB,iBAAmB,EACnB,KACF,CACF,CAGA,IAAI,aAAe,WAAW,KAAK,iBAAiB,EACpD,GAAI,EAAE,cAAgB,aAAa,OAAS,OAAS,aAAa,OAAS,OAAQ,CACjF,MAAM,IAAI,MAAM,+BAA+B,CACjD,CAEA,IAAI,YAAc,WAAW,KAAK,gBAAgB,EAClD,GAAI,EAAE,aAAe,YAAY,OAAS,OAAS,YAAY,OAAS,OAAQ,CAC9E,MAAM,IAAI,MAAM,8BAA8B,CAChD,CAIA,IAAI,UAAY,WAAW,KAAK,MAAM,kBAAmB,iBAAmB,CAAC,EAE7E,GAAI,UAAU,OAAS,KAAK,UAAW,CACrC,MAAM,IAAI,MAAM,+BAA+B,CACjD,CAEA,OAAO,SACT,EAiBA,4BAA4B,UAAU,aAAe,SAAS,OAAQ,YAAa,SAAU,CAC3F,IAAI,KAAO,KAEX,GAAI,CAAC,KAAK,IAAK,CACb,KAAK,eAAe,OAAQ,SAAU,UAAW,CAC/C,KAAK,aAAa,OAAQ,YAAa,QAAQ,CACjD,CAAC,EACD,MACF,CAEA,GAAI,KAAK,oBAAqB,CAC5B,MAAM,IAAI,MAAM,iIAAiI,CACnJ,CACA,KAAK,oBAAsB,KAE3B,OAAS,QAAQ,IAAI,sBAAsB,EAC3C,OAAS,QAAQ,KAAK,cAAc,EACpC,SAAS,OAAO,EAAG,CACjB,OAAS,GAAK,QAAQ,MAAM,CAAC,EAC7B,OAAS,QAAQ,QAAQ,cAAc,EACvC,KAAK,oBAAsB,MAC3B,SAAS,CAAC,CACZ,CAKA,GAAI,CACF,IAAI,qBAAuB,UAAY,CACrC,QAAQ,MAAM,+DAA+D,CAC/E,EACA,IAAI,aAAe,MAEnB,IAAI,GAAK,KAAK,IAAI,YAAY,CAAC,qBAAqB,EAAG,WAAW,EAClE,GAAG,WAAa,UAAW,CACzB,qBAAqB,EACrB,OAAO,EACP,GAAI,cAAgB,KAAK,QAAQ,eAAgB,CAC/C,KAAK,QAAQ,eAAe,CAC9B,CACF,EAEA,GAAG,QAAU,SAAS,EAAG,CACvB,OAAO,CAAC,CACV,EAEA,GAAG,QAAU,SAAS,EAAG,CACvB,OAAO,CAAC,CACV,EAEA,IAAI,MAAQ,GAAG,YAAY,qBAAqB,EAEhD,IAAI,YAAc,SAAU,YAAa,CACvC,GAAI,CACF,IAAI,YAAc,CAAC,YACnB,IAAI,UAAY,KAAK,aAAa,MAAO,YAAY,EAAG,YAAa,WAAW,EAEhF,qBAAuB,UAAW,CAChC,KAAK,mBAAqB,UAAU,cACpC,UAAU,qBAAqB,QAAQ,SAAU,eAAgB,CAC/D,KAAK,0BAA0B,eAAe,IAAI,EAAI,eAAe,SACvE,CAAC,CACH,EACA,GAAG,QAAU,GAAG,OAAO,CACzB,OAAS,MAAP,CACA,QAAQ,MAAM,2BAA4B,KAAK,EAC/C,GAAG,MAAM,CACX,CACF,EAYA,IAAI,mBAAqB,UAAW,CAGlC,OAAO,MAAM,WAAW,EAAG,SAAS,EAAG,CACrC,IAAI,YAAc,eAAe,EAAE,OAAO,MAAM,EAChD,YAAY,WAAW,CACzB,EAAG,SAAS,EAAG,CACb,QAAQ,MAAM,4BAA6B,CAAC,EAC5C,GAAG,MAAM,CACX,CAAC,CACH,EAEA,IAAI,gBAAkB,UAAW,CAC/B,OAAO,MAAM,IAAI,MAAM,EAAG,SAAS,EAAG,CACpC,GAAI,mBAAmB,EAAE,OAAO,MAAM,IAAM,KAAK,mBAAoB,CACnE,YAAY,CACd,KAAO,CACL,OAAS,QAAQ,KAAK,qDAAqD,EAC3E,aAAe,KACf,mBAAmB,CACrB,CACF,EAAG,SAAS,EAAG,CACb,QAAQ,MAAM,8BAA+B,CAAC,EAC9C,GAAG,MAAM,CACX,CAAC,CACH,EAEA,gBAAgB,CAClB,OAAS,MAAP,CACA,OAAO,KAAK,CACd,CACF,EAGA,SAAS,eAAe,QAAS,CAC/B,IAAI,YAAc,CAAC,EAEnB,QAAQ,QAAQ,SAAU,IAAK,CAC7B,IAAI,YAAc,IAAI,MAAM,GAAG,EAE/B,GAAI,YAAY,SAAW,GAAK,YAAY,CAAC,IAAM,QAAS,CAC1D,IAAI,WAAa,YAAY,CAAC,EAC9B,IAAI,QAAU,SAAS,YAAY,CAAC,CAAC,GAAK,EAC1C,IAAI,WAAa,YAAY,UAAU,EAEvC,GAAI,CAAC,YAAc,QAAU,WAAY,CACvC,YAAY,UAAU,EAAI,OAC5B,CACF,CACF,CAAC,EACD,OAAO,WACT,CAEA,SAAS,mBAAmB,MAAO,CACjC,GAAI,CACF,GAAI,MAAO,CACT,IAAI,KAAO,KAAK,MAAM,MAAM,KAAK,EACjC,OAAO,KAAK,cAAgB,IAC9B,KAAO,CACL,OAAO,IACT,CACF,OAAS,EAAP,CACA,QAAQ,MAAM,iCAAkC,CAAC,EACjD,OAAO,IACT,CACF,CAEA,4BAA4B,UAAU,aAAe,SAAS,SAAU,KAAM,YAAa,YAAa,CACtG,IAAI,KAAO,KACX,IAAI,qBAAuB,CAAC,EAC5B,IAAI,UAAY,EAEhB,IAAI,kBAAoB,SAAU,WAAY,EAAG,CAE/C,IAAI,YAAc,IAAI,IACtB,aAAe,WAAW,SAAS,QAAQ,SAAS,OAAQ,CAC1D,IAAI,QAAW,OAAS,KAAK,UAAa,EAC1C,YAAY,IAAI,OAAO,CACzB,CAAC,EACD,WAAW,SAAW,CAAC,EAGvB,IAAI,aAAe,SAAU,QAAS,CACpC,IAAI,UAAY,KAAK,UAAU,WAAY,OAAO,EAClD,GAAI,KAAK,QAAQ,eAAgB,CAC/B,UAAY,KAAK,QAAQ,eAAe,WAAW,KAAM,SAAS,CACpE,CAIA,UAAY,KAAK,UAAU,SAAS,EACpC,WAAa,UAAU,OACvB,OAAS,aAAe,QAAQ,IAAI,WAAa,WAAW,KAAO,UAAY,OAAO,EACtF,SAAS,IAAI,CACX,IAAK,WAAW,KAAO,UAAY,QACnC,MAAO,SACT,CAAC,CACH,EACA,GAAI,YAAa,CACf,YAAY,QAAQ,YAAY,CAClC,KAAO,CAEL,IAAI,WAAc,WAAW,MAAQ,KAAK,UAAa,EACvD,QAAS,EAAI,EAAG,GAAK,WAAY,GAAK,EAAG,CACvC,aAAa,CAAC,CAChB,CAKA,IAAI,oBAAsB,YAAY,WAAW,IAAI,GAAK,EAC1D,QAAS,EAAI,WAAa,EAAG,GAAK,oBAAqB,GAAK,EAAG,CAC7D,IAAI,iBAAmB,WAAW,KAAO,UAAY,EACrD,SAAS,OAAO,gBAAgB,EAChC,OAAS,QAAQ,KAAK,kBAAoB,gBAAgB,CAC5D,CACF,CAGA,GAAI,WAAW,OAAS,YAAY,MAAQ,CAAC,YAAa,CACxD,WAAW,QAAU,CAAC,EACtB,WAAW,KAAO,CAAC,EACnB,WAAW,aAAe,gBAAgB,EAC1C,qBAAqB,KAAK,CAAE,KAAM,WAAW,KAAM,UAAW,WAAW,YAAa,CAAC,EAEvF,IAAI,cAAgB,KAAK,UAAU,UAAU,EAC7C,WAAa,cAAc,OAC3B,OAAS,aAAe,QAAQ,IAAI,WAAa,WAAW,KAAO,WAAW,EAC9E,SAAS,IAAI,CACX,IAAK,WAAW,KAAO,YACvB,MAAO,aACT,CAAC,CACH,CAGA,KAAK,YAAY,CAAC,EAAI,CAAE,KAAM,WAAW,IAAK,CAChD,EACA,KAAK,YAAY,QAAQ,iBAAiB,EAE1C,KAAK,aAAe,gBAAgB,EACpC,IAAI,mBAAqB,KAAK,UAAU,IAAI,EAC5C,WAAa,mBAAmB,OAEhC,OAAS,aAAe,QAAQ,IAAI,cAAc,EAClD,SAAS,IAAI,CAAE,IAAK,OAAQ,MAAO,kBAAmB,CAAC,EAEvD,OAAS,QAAQ,IAAI,eAAiB,SAAS,EAC/C,MAAO,CACL,cAAe,KAAK,aACpB,oBACF,CACF,EAiBA,4BAA4B,UAAU,aAAe,SAAS,OAAQ,SAAU,CAC9E,IAAI,KAAO,KAEX,GAAI,KAAK,oBAAqB,CAC5B,MAAM,IAAI,MAAM,+HAA+H,CACjJ,CAEA,KAAK,oBAAsB,KAE3B,OAAS,QAAQ,IAAI,sBAAsB,EAC3C,OAAS,QAAQ,KAAK,cAAc,EAEpC,IAAI,OAAS,SAAU,MAAO,CAC5B,OAAS,QAAQ,QAAQ,cAAc,EACvC,KAAK,oBAAsB,MAC3B,SAAS,KAAK,CAChB,EAEA,KAAK,cAAc,OAAQ,SAAS,OAAQ,CAC1C,GAAI,CACF,GAAI,CAAC,MAAM,QAAQ,MAAM,EAAG,CAC1B,MAAM,MACR,CAEA,GAAI,CAAC,OAAO,OAAQ,CAClB,OAAO,OAAO,IAAI,CACpB,CAEA,OAAS,QAAQ,IAAI,gBAAiB,OAAO,MAAM,EAGnD,OAAS,YAAY,MAAM,EAC3B,IAAI,KAAO,OAAO,KAClB,OAAO,KAAO,KAGd,aAAa,KAAM,OAAO,SAAU,KAAK,QAAQ,iBAAkB,KAAK,eAAe,EACvF,OAAS,KAGT,KAAK,mBAAqB,KAAK,cAAgB,KAC/C,KAAK,0BAA4B,CAAC,EAClC,KAAK,YAAY,QAAQ,SAAU,WAAY,CAC7C,KAAK,0BAA0B,WAAW,IAAI,EAAI,WAAW,cAAgB,IAC/E,CAAC,EAED,OAAO,OAAO,IAAI,CACpB,OAAS,MAAP,CACA,KAAK,mBAAqB,KAC1B,KAAK,0BAA4B,CAAC,EAClC,OAAO,OAAO,KAAK,CACrB,CACF,CAAC,CACH,EAEA,SAAS,YAAY,OAAQ,CAC3B,IAAI,KACJ,IAAI,SAAW,CAAC,EAEhB,kBAAkB,MAAM,EAExB,OAAO,QAAQ,SAAS,MAAO,CAC7B,IAAI,KAAO,MAAM,KACjB,IAAI,MAAQ,MAAM,MAClB,IAAI,KAAO,MAAM,eACjB,GAAI,OAAS,OAAQ,CACnB,KAAO,KACT,SAAW,OAAS,OAAQ,CAC1B,GAAI,SAAS,IAAI,EAAG,CAClB,SAAS,IAAI,EAAE,WAAW,KAAK,KAAK,CACtC,KAAO,CACL,SAAS,IAAI,EAAI,CACf,SAAU,KACV,WAAY,CAAC,KAAK,CACpB,CACF,CACF,SAAW,OAAS,WAAY,CAC9B,GAAI,SAAS,IAAI,EAAG,CAClB,SAAS,IAAI,EAAE,SAAW,KAC5B,KAAO,CACL,SAAS,IAAI,EAAI,CAAE,SAAU,MAAO,WAAY,CAAC,CAAE,CACrD,CACF,KAAO,CACL,MAAM,IAAI,MAAM,aAAa,CAC/B,CACF,CAAC,EAED,GAAI,CAAC,KAAM,CACT,MAAM,IAAI,MAAM,gDAAgD,CAClE,CAEA,MAAO,CAAE,KAAY,QAAmB,CAC1C,CAEA,SAAS,aAAa,KAAM,SAAU,iBAAkB,gBAAiB,CACvE,KAAK,YAAY,QAAQ,SAAS,mBAAmB,eAAgB,EAAG,CACtE,IAAI,KAAO,eAAe,KAC1B,IAAI,gBAAkB,SAAS,IAAI,EACnC,GAAI,gBAAiB,CACnB,GAAI,CAAC,gBAAgB,SAAU,CAC7B,MAAM,IAAI,MAAM,mDAAqD,IAAI,CAC3E,CACA,IAAI,WAAa,gBAAgB,SACjC,gBAAgB,SAAW,KAC3B,KAAK,YAAY,CAAC,EAAI,WAEtB,IAAI,OAAS,gBAAgB,SAAS,IAAI,EAC1C,IAAI,gCAAkC,UAAY,CAChD,OAAS,QAAU,QAAQ,IAAI,gBAAkB,IAAI,EACrD,IAAI,KAAO,CAAC,EACZ,IAAI,WAAa,gBAAgB,WACjC,WAAW,QAAQ,SAAS,cAAc,MAAOA,GAAG,CAClD,GAAI,OAAQ,CACV,MAAQ,KAAK,MAAM,KAAK,EACxB,GAAI,iBAAkB,CACpB,MAAQ,iBAAiB,KAAM,KAAK,CACtC,CACF,CACA,MAAM,QAAQ,SAAS,IAAK,CAC1B,KAAK,KAAK,GAAG,CACf,CAAC,EACD,WAAWA,EAAC,EAAI,IAClB,CAAC,EACD,OAAO,IACT,EACA,WAAW,QAAU,+BACvB,CACF,CAAC,CACH,CAEA,4BAA4B,UAAU,eAAiB,SAAS,OAAQ,QAAS,UAAW,CAC1F,IAAI,KAAO,KACX,OAAS,QAAQ,IAAI,kBAAkB,EAEvC,GAAI,KAAK,kBAAmB,CAC1B,MAAM,IAAI,MAAM,2DAA2D,CAC7E,CACA,KAAK,kBAAoB,KAEzB,IAAI,YAAc,UAAU,KAAK,OAAQ,CAAC,EAE1C,YAAY,gBAAkB,SAAS,EAAG,CACxC,IAAI,GAAK,EAAE,OAAO,OAClB,OAAS,QAAQ,IAAI,iCAAmC,EAAE,UAAU,EAEpE,GAAI,EAAE,WAAa,EAAG,CAEpB,GAAG,kBAAkB,sBAAuB,CAAE,QAAS,KAAM,CAAC,CAChE,KAAO,CAEL,MAAM,IAAI,MAAM,uBAAyB,EAAE,WAAa,wBAAwB,CAClF,CACF,EAEA,YAAY,UAAY,SAAS,EAAG,CAClC,KAAK,kBAAoB,MACzB,IAAI,GAAK,EAAE,OAAO,OAClB,KAAK,IAAM,GAEX,GAAI,CAAC,GAAG,iBAAiB,SAAS,qBAAqB,EAAG,CACxD,QAAQ,IAAI,MAAM,6BAA6B,CAAC,EAEhD,KAAK,eAAe,MAAM,EAC1B,MACF,CAEA,OAAS,QAAQ,IAAI,cAAc,EAEnC,GAAG,gBAAkB,SAAS,mBAAoB,CAEhD,GAAI,KAAK,MAAQ,GAAI,CACnB,MACF,CAEA,OAAS,QAAQ,IAAI,qBAAsB,kBAAkB,EAO7D,KAAK,IAAI,MAAM,EACf,KAAK,IAAM,KACX,GAAI,KAAK,QAAQ,gBAAiB,CAChC,KAAK,QAAQ,gBAAgB,kBAAkB,CACjD,CACF,EAEA,UAAU,CACZ,EAEA,YAAY,UAAY,SAAS,EAAG,CAClC,QAAQ,MAAM,4BAA6B,CAAC,EAC5C,QAAQ,IAAI,MAAM,8CAA8C,CAAC,CACnE,EAEA,YAAY,QAAU,SAAS,EAAG,CAChC,KAAK,kBAAoB,MACzB,QAAQ,MAAM,uBAAwB,CAAC,EACvC,QAAQ,CAAC,CACX,CACF,EAEA,4BAA4B,UAAU,cAAgB,SAAS,OAAQ,SAAU,CAC/E,IAAI,KAAO,KACX,GAAI,CAAC,KAAK,IAAK,CACb,KAAK,eAAe,OAAQ,SAAU,UAAW,CAC/C,KAAK,cAAc,OAAQ,QAAQ,CACrC,CAAC,EACD,MACF,CAEA,IAAI,GAAK,KAAK,IAAI,YAAY,CAAC,qBAAqB,EAAG,UAAU,EACjE,IAAI,MAAQ,GAAG,YAAY,qBAAqB,EAEhD,IAAI,iBAAmB,KAAK,QAAQ,iBACpC,IAAI,gBAAkB,KAAK,gBAK3B,SAAS,cAAc,KAAM,CAC3B,IAAI,eAAiB,KAAK,eAC1B,IAAI,UAAY,gBAAgB,KAAM,cAAc,EAEpD,IAAI,UAAY,CAAC,EACjB,IAAI,mBAAqB,EAEzB,SAAS,iBAAiB,EAAG,eAAgB,SAAU,CAGrD,IAAI,UAAY,EAAE,OAAO,OACzB,UAAU,QAAQ,SAAU,MAAOA,GAAG,CACpC,WAAW,MAAO,iBAAkB,eAAe,EACnD,UAAU,KAAK,KAAK,EACpB,UAAUA,EAAC,EAAI,IACjB,CAAC,EAGD,oBAAsB,EACtB,GAAI,qBAAuB,eAAgB,CACzC,SAAS,SAAS,CACpB,CACF,CAIA,IAAI,eAAiB,EACrB,IAAI,kBAAoB,eAAiB,eACzC,SAAS,iBAAiB,MAAO,KAAM,CACrC,IAAI,SAAW,UAAU,KAAK,EAC9B,OAAO,MAAM,OAAO,QAAQ,EAAG,SAAS,EAAG,CACzC,GAAI,KAAO,eAAgB,CACzB,iBAAiB,MAAQ,kBAAmB,KAAO,CAAC,CACtD,CAEA,iBAAiB,EAAG,MAAO,QAAQ,CACrC,EAAG,SAAS,EAAG,CACb,SAAS,CAAC,CACZ,CAAC,CACH,CAEA,QAAS,EAAI,EAAG,EAAI,kBAAmB,GAAK,EAAG,CAC7C,iBAAiB,EAAG,CAAC,CACvB,CACF,CAEA,SAAS,cAAe,CACtB,OAAO,MAAM,OAAO,EAAG,SAAS,EAAG,CACjC,IAAI,UAAY,EAAE,OAAO,OACzB,UAAU,QAAQ,SAAU,MAAO,CACjC,WAAW,MAAO,iBAAkB,eAAe,CACrD,CAAC,EACD,SAAS,SAAS,CACpB,EAAG,SAAS,EAAG,CACb,SAAS,CAAC,CACZ,CAAC,CACH,CAEA,SAAS,YAAa,CACpB,SAAS,aAAa,KAAM,CAC1B,KAAK,KAAK,EACV,GAAI,KAAK,OAAS,IAAK,CACrB,cAAc,IAAI,CACpB,KAAO,CACL,aAAa,CACf,CACF,CAEA,OAAO,MAAM,WAAW,EAAG,SAAS,EAAG,CACrC,aAAa,EAAE,OAAO,MAAM,CAC9B,EAAG,SAAS,EAAG,CACb,SAAS,CAAC,CACZ,CAAC,EAED,GAAI,KAAK,QAAQ,aAAc,CAC7B,KAAK,QAAQ,aAAa,CAC5B,CACF,CAEA,WAAW,CACb,EAEA,SAAS,cAAc,MAAO,CAC5B,IAAI,IAAM,MAAM,IAEhB,GAAI,MAAQ,OAAQ,CAClB,MAAM,KAAO,OACb,MACF,SAAW,IAAI,SAAS,GAAG,EAAG,CAC5B,IAAI,YAAc,IAAI,MAAM,GAAG,EAC/B,GAAI,YAAY,SAAW,GAAK,YAAY,CAAC,IAAM,QAAS,CAC1D,MAAM,KAAO,OACb,MAAM,eAAiB,YAAY,CAAC,EACpC,MAAM,MAAQ,SAAS,YAAY,CAAC,EAAG,EAAE,EACzC,MACF,SAAW,YAAY,SAAW,GAAK,YAAY,CAAC,IAAM,WAAY,CACpE,MAAM,KAAO,WACb,MAAM,eAAiB,YAAY,CAAC,EACpC,MACF,CACF,CAEA,QAAQ,MAAM,iBAAmB,GAAG,EACpC,MAAM,IAAI,MAAM,0CAA0C,CAC5D,CAEA,SAAS,WAAW,MAAO,iBAAkB,gBAAiB,CAC5D,cAAc,KAAK,EAEnB,IAAI,OAAS,MAAM,OAAS,OAC5B,IAAI,OAAS,gBAAgB,SAAS,MAAM,cAAc,EAE1D,GAAI,EAAE,QAAU,QAAS,CACvB,MAAM,MAAQ,KAAK,MAAM,MAAM,KAAK,CACtC,CACA,GAAI,kBAAoB,QAAU,CAAC,OAAQ,CACzC,MAAM,MAAQ,iBAAiB,MAAM,eAAgB,MAAM,KAAK,CAClE,CACF,CAgBA,4BAA4B,UAAU,eAAiB,SAAS,OAAQ,SAAU,CAChF,GAAI,KAAK,oBAAqB,CAC5B,MAAM,IAAI,MAAM,gIAAgI,CAClJ,CAEA,KAAK,oBAAsB,KAE3B,IAAI,KAAO,KACX,OAAS,QAAQ,IAAI,wBAAwB,EAC7C,OAAS,QAAQ,KAAK,gBAAgB,EAEtC,KAAK,mBAAqB,KAC1B,KAAK,0BAA4B,CAAC,EAElC,GAAI,KAAK,IAAK,CACZ,KAAK,IAAI,MAAM,EACf,KAAK,IAAM,IACb,CAEA,IAAI,QAAU,UAAU,eAAe,MAAM,EAE7C,QAAQ,UAAY,UAAW,CAC7B,KAAK,oBAAsB,MAC3B,OAAS,QAAQ,QAAQ,gBAAgB,EACzC,SAAS,CAAE,QAAS,IAAK,CAAC,CAC5B,EAEA,QAAQ,QAAU,SAAS,EAAG,CAC5B,KAAK,oBAAsB,MAC3B,QAAQ,MAAM,gCAAiC,CAAC,EAChD,SAAS,CAAE,QAAS,KAAM,CAAC,CAC7B,EAEA,QAAQ,UAAY,SAAS,EAAG,CAG9B,QAAQ,MAAM,sEAAuE,CAAC,CACxF,CACF,EAEA,SAAS,iBAAkB,CAIzB,OAAO,KAAK,OAAO,EAAE,SAAS,EAAE,EAAE,UAAU,CAAC,CAC/C,CAEA,SAAS,kBAAkB,OAAQ,CAGjC,OAAO,KAAK,SAAS,EAAG,EAAG,CACzB,OAAQ,EAAE,OAAS,IAAM,EAAE,OAAS,EACtC,CAAC,CACH,CAEA,SAAS,gBAAgB,KAAM,MAAO,CACpC,IAAI,cAAgB,KAAK,MAAM,KAAK,OAAS,KAAK,EAClD,IAAI,UAAY,CAAC,EACjB,IAAI,OAAQ,OACZ,QAAS,EAAI,EAAG,EAAI,MAAO,GAAK,EAAG,CACjC,OAAS,KAAK,cAAgB,CAAC,EAC/B,OAAS,KAAK,eAAiB,EAAI,EAAE,EACrC,GAAI,IAAM,EAAG,CAEX,UAAU,KAAK,YAAY,WAAW,OAAQ,IAAI,CAAC,CACrD,SAAW,IAAM,MAAQ,EAAG,CAE1B,UAAU,KAAK,YAAY,WAAW,MAAM,CAAC,CAC/C,KAAO,CAEL,UAAU,KAAK,YAAY,MAAM,OAAQ,OAAQ,MAAO,IAAI,CAAC,CAC/D,CACF,CACA,OAAO,SACT,CAEA,SAAS,OAAO,QAAS,UAAW,QAAS,CAC3C,QAAQ,UAAY,SAAU,EAAG,CAC/B,GAAI,CACF,OAAO,UAAU,CAAC,CACpB,OAAS,MAAP,CACA,QAAQ,KAAK,CACf,CACF,EACA,QAAQ,QAAU,QAClB,OAAO,OACT,CAEA,OAAO,2BACT,EAAG,CACL,CAAC",
  "names": ["i"]
}
